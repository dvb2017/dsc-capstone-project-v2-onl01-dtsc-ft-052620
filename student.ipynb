{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project\n",
    "\n",
    "## Introduction\n",
    "The business care here is a bit different than previous projects.  Rather than focusing solely on an in depth analysis of the data in order to answer a question, my goal is to create a data tool and incorporate the analysis into that. Specifically, I would like to create an interface that provides a wealth of information about stock market prices.  It should be simple to use and provide a high level of interactivity.  As this is a data science project, there will also be an emphasis on machine learning and how it could be used to predict future prices.  Additionally, there were two specific topics I wanted to examine and visualize, these were yield rates and economic sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary packages\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta, date\n",
    "from urllib.error import HTTPError\n",
    "import statsmodels.stats as smstat\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.plotting import lag_plot\n",
    "import numpy as np\n",
    "import random\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as pltdates\n",
    "from matplotlib.pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "import pmdarima as pm\n",
    "from pmdarima.model_selection import train_test_split\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt, log\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a class in order to scrape data from Yahoo Finance\n",
    "class YahooFinanceHistory:\n",
    "    timeout = 2\n",
    "    crumb_link = 'https://finance.yahoo.com/quote/{0}/history?p={0}'\n",
    "    crumble_regex = r'CrumbStore\":{\"crumb\":\"(.*?)\"}'\n",
    "    quote_link = 'https://query1.finance.yahoo.com/v7/finance/download/{quote}?period1={dfrom}&period2={dto}&interval=1d&events=history&crumb={crumb}'\n",
    "\n",
    "    def __init__(self, symbol, days_back=7):\n",
    "        self.symbol = symbol\n",
    "        self.session = requests.Session()\n",
    "        self.dt = timedelta(days=days_back)\n",
    "\n",
    "    def get_crumb(self):\n",
    "        response = self.session.get(self.crumb_link.format(self.symbol), timeout=self.timeout)\n",
    "        response.raise_for_status()\n",
    "        match = re.search(self.crumble_regex, response.text)\n",
    "        if not match:\n",
    "            raise ValueError('Could not get crumb from Yahoo Finance')\n",
    "        else:\n",
    "            self.crumb = match.group(1)\n",
    "\n",
    "    def get_quote(self):\n",
    "        if not hasattr(self, 'crumb') or len(self.session.cookies) == 0:\n",
    "            self.get_crumb()\n",
    "        now = datetime.utcnow()\n",
    "        dateto = int(now.timestamp())\n",
    "        datefrom = int((now - self.dt).timestamp())\n",
    "        url = self.quote_link.format(quote=self.symbol, dfrom=datefrom, dto=dateto, crumb=self.crumb)\n",
    "        response = self.session.get(url)\n",
    "        response.raise_for_status()\n",
    "        return pd.read_csv(StringIO(response.text), parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a root mean squared error function for later\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(round(rmse, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>lastsale</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>ipoyear</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>summary quote</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDD</td>\n",
       "      <td>3D Systems Corporation</td>\n",
       "      <td>6.69</td>\n",
       "      <td>$810.39M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Computer Software: Prepackaged Software</td>\n",
       "      <td>https://old.nasdaq.com/symbol/ddd</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>169.30</td>\n",
       "      <td>$97.52B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Medical/Dental Instruments</td>\n",
       "      <td>https://old.nasdaq.com/symbol/mmm</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WBAI</td>\n",
       "      <td>500.com Limited</td>\n",
       "      <td>2.98</td>\n",
       "      <td>$128.14M</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Services-Misc. Amusement &amp; Recreation</td>\n",
       "      <td>https://old.nasdaq.com/symbol/wbai</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGHT</td>\n",
       "      <td>8x8 Inc</td>\n",
       "      <td>16.49</td>\n",
       "      <td>$1.72B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>EDP Services</td>\n",
       "      <td>https://old.nasdaq.com/symbol/eght</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHC</td>\n",
       "      <td>A.H. Belo Corporation</td>\n",
       "      <td>1.45</td>\n",
       "      <td>$34.63M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Newspapers/Magazines</td>\n",
       "      <td>https://old.nasdaq.com/symbol/ahc</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                    name  lastsale marketcap  ipoyear  \\\n",
       "0    DDD  3D Systems Corporation      6.69  $810.39M      NaN   \n",
       "1    MMM              3M Company    169.30   $97.52B      NaN   \n",
       "2   WBAI         500.com Limited      2.98  $128.14M   2013.0   \n",
       "3   EGHT                 8x8 Inc     16.49    $1.72B      NaN   \n",
       "4    AHC   A.H. Belo Corporation      1.45   $34.63M      NaN   \n",
       "\n",
       "              sector                                 industry  \\\n",
       "0         Technology  Computer Software: Prepackaged Software   \n",
       "1        Health Care               Medical/Dental Instruments   \n",
       "2  Consumer Services    Services-Misc. Amusement & Recreation   \n",
       "3         Technology                             EDP Services   \n",
       "4  Consumer Services                     Newspapers/Magazines   \n",
       "\n",
       "                        summary quote exchange  \n",
       "0   https://old.nasdaq.com/symbol/ddd     nyse  \n",
       "1   https://old.nasdaq.com/symbol/mmm     nyse  \n",
       "2  https://old.nasdaq.com/symbol/wbai     nyse  \n",
       "3  https://old.nasdaq.com/symbol/eght     nyse  \n",
       "4   https://old.nasdaq.com/symbol/ahc     nyse  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing stock exchange datasets\n",
    "nasdaq_df = pd.read_csv('nasdaq_list.csv')\n",
    "nyse_df = pd.read_csv('nyse_list.csv')\n",
    "nasdaq_df['exchange'] = 'nasdaq'\n",
    "nyse_df['exchange'] = 'nyse'\n",
    "comb_names = pd.concat([nyse_df, nasdaq_df], ignore_index=True)\n",
    "comb_names.rename(str.lower, axis='columns', inplace=True)\n",
    "comb_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>lastsale</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>ipoyear</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>summary quote</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDD</td>\n",
       "      <td>3D Systems Corporation</td>\n",
       "      <td>6.69</td>\n",
       "      <td>$810.39M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Computer Software: Prepackaged Software</td>\n",
       "      <td>https://old.nasdaq.com/symbol/ddd</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>169.30</td>\n",
       "      <td>$97.52B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Medical/Dental Instruments</td>\n",
       "      <td>https://old.nasdaq.com/symbol/mmm</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WBAI</td>\n",
       "      <td>500.com Limited</td>\n",
       "      <td>2.98</td>\n",
       "      <td>$128.14M</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Services-Misc. Amusement &amp; Recreation</td>\n",
       "      <td>https://old.nasdaq.com/symbol/wbai</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGHT</td>\n",
       "      <td>8x8 Inc</td>\n",
       "      <td>16.49</td>\n",
       "      <td>$1.72B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>EDP Services</td>\n",
       "      <td>https://old.nasdaq.com/symbol/eght</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHC</td>\n",
       "      <td>A.H. Belo Corporation</td>\n",
       "      <td>1.45</td>\n",
       "      <td>$34.63M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Newspapers/Magazines</td>\n",
       "      <td>https://old.nasdaq.com/symbol/ahc</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                    name  lastsale marketcap  ipoyear  \\\n",
       "0    DDD  3D Systems Corporation      6.69  $810.39M      NaN   \n",
       "1    MMM              3M Company    169.30   $97.52B      NaN   \n",
       "2   WBAI         500.com Limited      2.98  $128.14M   2013.0   \n",
       "3   EGHT                 8x8 Inc     16.49    $1.72B      NaN   \n",
       "4    AHC   A.H. Belo Corporation      1.45   $34.63M      NaN   \n",
       "\n",
       "              sector                                 industry  \\\n",
       "0         Technology  Computer Software: Prepackaged Software   \n",
       "1        Health Care               Medical/Dental Instruments   \n",
       "2  Consumer Services    Services-Misc. Amusement & Recreation   \n",
       "3         Technology                             EDP Services   \n",
       "4  Consumer Services                     Newspapers/Magazines   \n",
       "\n",
       "                        summary quote exchange  \n",
       "0   https://old.nasdaq.com/symbol/ddd     nyse  \n",
       "1   https://old.nasdaq.com/symbol/mmm     nyse  \n",
       "2  https://old.nasdaq.com/symbol/wbai     nyse  \n",
       "3  https://old.nasdaq.com/symbol/eght     nyse  \n",
       "4   https://old.nasdaq.com/symbol/ahc     nyse  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing and dropping duplicates\n",
    "dupe_list = comb_names.duplicated(subset=['symbol'])\n",
    "dupes = []\n",
    "for x in range(len(dupe_list)):\n",
    "    if dupe_list[x] == True:\n",
    "        dupes.append(x)\n",
    "new_names = comb_names.drop(dupes)\n",
    "new_names.reset_index(drop=True, inplace=True)\n",
    "new_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>$97.52B</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A.O Smith Corporation</td>\n",
       "      <td>$9.23B</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAN</td>\n",
       "      <td>Aaron&amp;#39;s,  Inc.</td>\n",
       "      <td>$3.94B</td>\n",
       "      <td>Technology</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABB</td>\n",
       "      <td>ABB Ltd</td>\n",
       "      <td>$57.15B</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>$194.14B</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                   name marketcap             sector exchange\n",
       "0    MMM             3M Company   $97.52B        Health Care     nyse\n",
       "1    AOS  A.O Smith Corporation    $9.23B  Consumer Durables     nyse\n",
       "2    AAN     Aaron&#39;s,  Inc.    $3.94B         Technology     nyse\n",
       "3    ABB                ABB Ltd   $57.15B  Consumer Durables     nyse\n",
       "4    ABT    Abbott Laboratories  $194.14B        Health Care     nyse"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning- filtering out small companies, dropping columns, \n",
    "#Dropping NA values\n",
    "mid_cap = new_names.copy()\n",
    "drop_list = []\n",
    "for x in range(len(mid_cap['marketcap'])):\n",
    "    cap_value = str(mid_cap['marketcap'][x])\n",
    "    if cap_value[-1] == 'M':\n",
    "        drop_list.append(x)\n",
    "    elif cap_value[-1] == 'B' and cap_value[:3] == '$1.':\n",
    "        drop_list.append(x)\n",
    "mid_cap.drop(drop_list, inplace=True)\n",
    "mid_cap = mid_cap[mid_cap['marketcap'].notna()]\n",
    "mid_cap = mid_cap[mid_cap['sector'].notna()]\n",
    "mid_cap = mid_cap.drop(columns=['ipoyear', 'lastsale', 'summary quote', 'industry'])\n",
    "mid_cap.reset_index(drop=True, inplace=True)\n",
    "mid_cap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting list of all symbols and using it to scrape the web for stock data\n",
    "symbol_list = mid_cap['symbol']\n",
    "for x in symbol_list:\n",
    "    try:\n",
    "        temp_df = YahooFinanceHistory(x, days_back=365).get_quote()\n",
    "        temp_df['symbol'] = x\n",
    "        if x == symbol_list[0]:\n",
    "            new_df = temp_df\n",
    "        else:\n",
    "            new_df = pd.concat([new_df, temp_df], ignore_index=True)\n",
    "    except:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NaN stocks\n",
    "midcap_data = new_df.copy()\n",
    "na_stocks = midcap_data[midcap_data['Open'].isna()]\n",
    "na_unique = na_stocks['symbol'].unique()\n",
    "for x in na_unique:\n",
    "    na_temp = midcap_data[midcap_data['symbol'] == x]\n",
    "    midcap_data.drop(na_temp.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick list of unique dates in the dataset\n",
    "#Removing stocks that don't cover the full date range\n",
    "date_list = np.array(midcap_data['Date'].unique(), dtype='datetime64[D]')\n",
    "for x in midcap_data['symbol'].unique():\n",
    "    temp_df = midcap_data[midcap_data['symbol']==x]\n",
    "    if temp_df['Date'].min() > min(date_list):\n",
    "        midcap_data.drop(temp_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line to export midcap_data, currently marked as comment\n",
    "#Because it has already been exported\n",
    "#midcap_data.to_csv(r'C:\\Users\\derek\\capstone_project\\midcap_data.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MMM</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>168.509995</td>\n",
       "      <td>168.559998</td>\n",
       "      <td>163.550003</td>\n",
       "      <td>164.990005</td>\n",
       "      <td>159.066010</td>\n",
       "      <td>2653100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>166.940002</td>\n",
       "      <td>170.149994</td>\n",
       "      <td>166.720001</td>\n",
       "      <td>170.089996</td>\n",
       "      <td>163.982880</td>\n",
       "      <td>2467400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04</th>\n",
       "      <td>171.619995</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>171.619995</td>\n",
       "      <td>174.899994</td>\n",
       "      <td>168.620193</td>\n",
       "      <td>4142800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.460007</td>\n",
       "      <td>173.770004</td>\n",
       "      <td>175.270004</td>\n",
       "      <td>168.976898</td>\n",
       "      <td>2304300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>174.910004</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>172.360001</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>167.752502</td>\n",
       "      <td>3012900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open        high         low       close   adj_close  \\\n",
       "symbol date                                                                     \n",
       "MMM    2019-10-31  168.509995  168.559998  163.550003  164.990005  159.066010   \n",
       "       2019-11-01  166.940002  170.149994  166.720001  170.089996  163.982880   \n",
       "       2019-11-04  171.619995  175.000000  171.619995  174.899994  168.620193   \n",
       "       2019-11-05  175.000000  175.460007  173.770004  175.270004  168.976898   \n",
       "       2019-11-06  174.910004  175.000000  172.360001  174.000000  167.752502   \n",
       "\n",
       "                      volume  \n",
       "symbol date                   \n",
       "MMM    2019-10-31  2653100.0  \n",
       "       2019-11-01  2467400.0  \n",
       "       2019-11-04  4142800.0  \n",
       "       2019-11-05  2304300.0  \n",
       "       2019-11-06  3012900.0  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making columns lowercase, removing spacing\n",
    "test_ind = midcap_data.copy()\n",
    "test_ind.rename(str.lower, axis='columns', inplace=True)\n",
    "test_ind.rename(columns={'adj close':'adj_close'}, inplace=True)\n",
    "test_ind = test_ind.set_index(['symbol', 'date'])\n",
    "test_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>diff</th>\n",
       "      <th>pct_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.120003</td>\n",
       "      <td>75.099998</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>75.105080</td>\n",
       "      <td>970500.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.328947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>76.510002</td>\n",
       "      <td>77.349998</td>\n",
       "      <td>76.320000</td>\n",
       "      <td>76.970001</td>\n",
       "      <td>76.314690</td>\n",
       "      <td>1106300.0</td>\n",
       "      <td>0.459999</td>\n",
       "      <td>0.601227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04</th>\n",
       "      <td>77.680000</td>\n",
       "      <td>77.849998</td>\n",
       "      <td>76.730003</td>\n",
       "      <td>76.739998</td>\n",
       "      <td>76.086647</td>\n",
       "      <td>1010200.0</td>\n",
       "      <td>-0.940002</td>\n",
       "      <td>-1.210095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>76.820000</td>\n",
       "      <td>76.910004</td>\n",
       "      <td>75.470001</td>\n",
       "      <td>75.550003</td>\n",
       "      <td>74.906784</td>\n",
       "      <td>2362700.0</td>\n",
       "      <td>-1.269997</td>\n",
       "      <td>-1.653211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>75.699997</td>\n",
       "      <td>75.940002</td>\n",
       "      <td>74.940002</td>\n",
       "      <td>75.790001</td>\n",
       "      <td>75.144737</td>\n",
       "      <td>1355700.0</td>\n",
       "      <td>0.090004</td>\n",
       "      <td>0.118896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open       high        low      close  adj_close  \\\n",
       "symbol date                                                                \n",
       "A      2019-10-31  76.000000  76.120003  75.099998  75.750000  75.105080   \n",
       "       2019-11-01  76.510002  77.349998  76.320000  76.970001  76.314690   \n",
       "       2019-11-04  77.680000  77.849998  76.730003  76.739998  76.086647   \n",
       "       2019-11-05  76.820000  76.910004  75.470001  75.550003  74.906784   \n",
       "       2019-11-06  75.699997  75.940002  74.940002  75.790001  75.144737   \n",
       "\n",
       "                      volume      diff  pct_change  \n",
       "symbol date                                         \n",
       "A      2019-10-31   970500.0 -0.250000   -0.328947  \n",
       "       2019-11-01  1106300.0  0.459999    0.601227  \n",
       "       2019-11-04  1010200.0 -0.940002   -1.210095  \n",
       "       2019-11-05  2362700.0 -1.269997   -1.653211  \n",
       "       2019-11-06  1355700.0  0.090004    0.118896  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting multiindex and adding two new columns\n",
    "test_ind2 = test_ind.copy()\n",
    "test_ind2['diff'] = 0\n",
    "multi_index = pd.MultiIndex.from_tuples(test_ind2.index, names=['symbol', 'date'])\n",
    "test_ind2.reindex(multi_index)\n",
    "test_ind2.sort_index(level=['symbol','date'], ascending=True, inplace=True)\n",
    "test_ind2['diff'] = test_ind2['close'] - test_ind2['open']\n",
    "test_ind2['pct_change'] = test_ind2['diff'] / test_ind2['open'] *100\n",
    "test_ind2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>diff</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>move_avg_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.120003</td>\n",
       "      <td>75.099998</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>75.105080</td>\n",
       "      <td>970500.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.328947</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>76.510002</td>\n",
       "      <td>77.349998</td>\n",
       "      <td>76.320000</td>\n",
       "      <td>76.970001</td>\n",
       "      <td>76.314690</td>\n",
       "      <td>1106300.0</td>\n",
       "      <td>0.459999</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04</th>\n",
       "      <td>77.680000</td>\n",
       "      <td>77.849998</td>\n",
       "      <td>76.730003</td>\n",
       "      <td>76.739998</td>\n",
       "      <td>76.086647</td>\n",
       "      <td>1010200.0</td>\n",
       "      <td>-0.940002</td>\n",
       "      <td>-1.210095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>76.820000</td>\n",
       "      <td>76.910004</td>\n",
       "      <td>75.470001</td>\n",
       "      <td>75.550003</td>\n",
       "      <td>74.906784</td>\n",
       "      <td>2362700.0</td>\n",
       "      <td>-1.269997</td>\n",
       "      <td>-1.653211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>75.699997</td>\n",
       "      <td>75.940002</td>\n",
       "      <td>74.940002</td>\n",
       "      <td>75.790001</td>\n",
       "      <td>75.144737</td>\n",
       "      <td>1355700.0</td>\n",
       "      <td>0.090004</td>\n",
       "      <td>0.118896</td>\n",
       "      <td>-0.494426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open       high        low      close  adj_close  \\\n",
       "symbol date                                                                \n",
       "A      2019-10-31  76.000000  76.120003  75.099998  75.750000  75.105080   \n",
       "       2019-11-01  76.510002  77.349998  76.320000  76.970001  76.314690   \n",
       "       2019-11-04  77.680000  77.849998  76.730003  76.739998  76.086647   \n",
       "       2019-11-05  76.820000  76.910004  75.470001  75.550003  74.906784   \n",
       "       2019-11-06  75.699997  75.940002  74.940002  75.790001  75.144737   \n",
       "\n",
       "                      volume      diff  pct_change  move_avg_7  \n",
       "symbol date                                                     \n",
       "A      2019-10-31   970500.0 -0.250000   -0.328947    0.000000  \n",
       "       2019-11-01  1106300.0  0.459999    0.601227    0.000000  \n",
       "       2019-11-04  1010200.0 -0.940002   -1.210095    0.000000  \n",
       "       2019-11-05  2362700.0 -1.269997   -1.653211    0.000000  \n",
       "       2019-11-06  1355700.0  0.090004    0.118896   -0.494426  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a moving average column\n",
    "test_ind2['move_avg_7'] = 0\n",
    "for x,y in test_ind2.index:\n",
    "    if y >= test_ind2.index[4][1]:\n",
    "        if y.weekday() != 4:\n",
    "            first_day = y - timedelta(days=6)\n",
    "            test_ind2.loc[(x, y),'move_avg_7'] = \\\n",
    "            test_ind2.loc[(x, first_day):(x, y), 'pct_change'].mean()\n",
    "        elif y.weekday() == 4:\n",
    "            first_day = y - timedelta(days=4) \n",
    "            test_ind2.loc[(x, y),'move_avg_7'] = \\\n",
    "            test_ind2.loc[(x, first_day):(x, y), 'pct_change'].mean()\n",
    "        \n",
    "test_ind2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the difference between each stock's start and end date\n",
    "sym_list = list(test_ind2.index.get_level_values(0).unique())\n",
    "delta_list = []\n",
    "for x in sym_list:\n",
    "    start_val = test_ind2.loc[(x, test_ind2.loc[x].index.min()), 'open']\n",
    "    end_val = test_ind2.loc[(x, test_ind2.loc[x].index.max()), 'close'] \n",
    "    delta_list.append(end_val-start_val)\n",
    "deltarray = np.array(delta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>26.019997</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>-8.190001</td>\n",
       "      <td>Basic Industries</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>-18.910000</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>nasdaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAN</th>\n",
       "      <td>-21.980000</td>\n",
       "      <td>Technology</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAON</th>\n",
       "      <td>12.329998</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nasdaq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            delta            sector exchange\n",
       "symbol                                      \n",
       "A       26.019997     Capital Goods     nyse\n",
       "AA      -8.190001  Basic Industries     nyse\n",
       "AAL    -18.910000    Transportation   nasdaq\n",
       "AAN    -21.980000        Technology     nyse\n",
       "AAON    12.329998     Capital Goods   nasdaq"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a reference dataframe for time independent columns\n",
    "sym_delta = pd.DataFrame({'symbol':sym_list, 'delta':deltarray})\n",
    "sym_delta.set_index('symbol', drop=True, inplace=True)\n",
    "new_midcap = mid_cap.set_index('symbol', drop=True)\n",
    "sym_delta['sector'] = 0\n",
    "sym_delta['exchange'] = 0\n",
    "for x in sym_delta.index:\n",
    "    sym_delta.loc[x,'sector'] = new_midcap.loc[x, 'sector']\n",
    "    sym_delta.loc[x,'exchange'] = new_midcap.loc[x, 'exchange']\n",
    "sym_delta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding several new columns to the dataframe\n",
    "test_ind2['delta'] = 0\n",
    "test_ind2['delta_pct'] = 0\n",
    "test_ind2['sector'] = 0\n",
    "test_ind2['exchange'] = 0\n",
    "for x in sym_delta.index:\n",
    "    test_ind2.loc[x, 'delta'] = sym_delta.loc[x, 'delta']\n",
    "    test_ind2.loc[x, 'sector'] = sym_delta.loc[x, 'sector']\n",
    "    test_ind2.loc[x, 'exchange'] = sym_delta.loc[x, 'exchange']\n",
    "    test_ind2.loc[x, 'delta_pct'] = sym_delta.loc[x, 'delta'] \\\n",
    "    / test_ind2.loc[(x, test_ind2.loc[x].index.min()), 'open'] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>move_avg_7</th>\n",
       "      <th>delta_pct</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>intra_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>-0.328947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.236838</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "      <td>1.342112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>76.510002</td>\n",
       "      <td>76.970001</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.236838</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "      <td>1.346227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04</th>\n",
       "      <td>77.680000</td>\n",
       "      <td>76.739998</td>\n",
       "      <td>-1.210095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.236838</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "      <td>1.441806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>76.820000</td>\n",
       "      <td>75.550003</td>\n",
       "      <td>-1.653211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.236838</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "      <td>1.874516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>75.699997</td>\n",
       "      <td>75.790001</td>\n",
       "      <td>0.118896</td>\n",
       "      <td>-0.494426</td>\n",
       "      <td>34.236838</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "      <td>1.321004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open      close  pct_change  move_avg_7  delta_pct  \\\n",
       "symbol date                                                                  \n",
       "A      2019-10-31  76.000000  75.750000   -0.328947    0.000000  34.236838   \n",
       "       2019-11-01  76.510002  76.970001    0.601227    0.000000  34.236838   \n",
       "       2019-11-04  77.680000  76.739998   -1.210095    0.000000  34.236838   \n",
       "       2019-11-05  76.820000  75.550003   -1.653211    0.000000  34.236838   \n",
       "       2019-11-06  75.699997  75.790001    0.118896   -0.494426  34.236838   \n",
       "\n",
       "                          sector exchange  intra_pct  \n",
       "symbol date                                           \n",
       "A      2019-10-31  Capital Goods     nyse   1.342112  \n",
       "       2019-11-01  Capital Goods     nyse   1.346227  \n",
       "       2019-11-04  Capital Goods     nyse   1.441806  \n",
       "       2019-11-05  Capital Goods     nyse   1.874516  \n",
       "       2019-11-06  Capital Goods     nyse   1.321004  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping columns used for calculations\n",
    "#And other unneeded columns\n",
    "test_ind3 = test_ind2.copy()\n",
    "test_ind3['intra_rng'] = test_ind3['high'] - test_ind3['low']\n",
    "test_ind3['intra_pct'] = test_ind3['intra_rng'] / test_ind3['open'] *100\n",
    "test_ind3.drop(columns=['high', 'low', 'adj_close', 'volume', 'diff', 'delta', 'intra_rng'], inplace=True)\n",
    "test_ind3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>move_avg_7</th>\n",
       "      <th>delta_pct</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>intra_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>102.27</td>\n",
       "      <td>102.02</td>\n",
       "      <td>-0.244451</td>\n",
       "      <td>-0.742499</td>\n",
       "      <td>34.2368</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "      <td>2.23428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>12.21</td>\n",
       "      <td>12.75</td>\n",
       "      <td>4.4226</td>\n",
       "      <td>-0.0552178</td>\n",
       "      <td>-39.1118</td>\n",
       "      <td>Basic Industries</td>\n",
       "      <td>nyse</td>\n",
       "      <td>5.24161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>10.96</td>\n",
       "      <td>11.16</td>\n",
       "      <td>1.82482</td>\n",
       "      <td>-2.11402</td>\n",
       "      <td>-62.8866</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>nasdaq</td>\n",
       "      <td>3.64964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAN</th>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>54.95</td>\n",
       "      <td>54.76</td>\n",
       "      <td>-0.345774</td>\n",
       "      <td>-0.764469</td>\n",
       "      <td>-28.6422</td>\n",
       "      <td>Technology</td>\n",
       "      <td>nyse</td>\n",
       "      <td>7.91628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAON</th>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>57.1</td>\n",
       "      <td>58.98</td>\n",
       "      <td>3.29247</td>\n",
       "      <td>-0.07755</td>\n",
       "      <td>26.4309</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nasdaq</td>\n",
       "      <td>4.60596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open   close pct_change move_avg_7 delta_pct  \\\n",
       "A    2020-10-29  102.27  102.02  -0.244451  -0.742499   34.2368   \n",
       "AA   2020-10-29   12.21   12.75     4.4226 -0.0552178  -39.1118   \n",
       "AAL  2020-10-29   10.96   11.16    1.82482   -2.11402  -62.8866   \n",
       "AAN  2020-10-29   54.95   54.76  -0.345774  -0.764469  -28.6422   \n",
       "AAON 2020-10-29    57.1   58.98    3.29247   -0.07755   26.4309   \n",
       "\n",
       "                           sector exchange intra_pct  \n",
       "A    2020-10-29     Capital Goods     nyse   2.23428  \n",
       "AA   2020-10-29  Basic Industries     nyse   5.24161  \n",
       "AAL  2020-10-29    Transportation   nasdaq   3.64964  \n",
       "AAN  2020-10-29        Technology     nyse   7.91628  \n",
       "AAON 2020-10-29     Capital Goods   nasdaq   4.60596  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe of only the last date\n",
    "#Also making one for the first date\n",
    "for x in sym_delta.index:\n",
    "    open_val = pd.DataFrame(test_ind3.loc[(x, test_ind3.loc[x].index.min())]) \n",
    "    close_val = pd.DataFrame(test_ind3.loc[(x, test_ind3.loc[x].index.max())]) \n",
    "    if x == sym_delta.index[0]:\n",
    "        open_df = open_val.T\n",
    "        close_df = close_val.T\n",
    "    else:\n",
    "        open_df = pd.concat([open_df, open_val.T])\n",
    "        close_df = pd.concat([close_df, close_val.T])\n",
    "close_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>delta_pct</th>\n",
       "      <th>intra_pct</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.123025</td>\n",
       "      <td>34.236838</td>\n",
       "      <td>2.376618</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>-0.210734</td>\n",
       "      <td>-39.111751</td>\n",
       "      <td>5.697919</td>\n",
       "      <td>Basic Industries</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>-0.580924</td>\n",
       "      <td>-62.886598</td>\n",
       "      <td>6.465470</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>nasdaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAN</th>\n",
       "      <td>-0.142530</td>\n",
       "      <td>-28.642169</td>\n",
       "      <td>5.012361</td>\n",
       "      <td>Technology</td>\n",
       "      <td>nyse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAON</th>\n",
       "      <td>0.179401</td>\n",
       "      <td>26.430863</td>\n",
       "      <td>3.699973</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>nasdaq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pct_change  delta_pct  intra_pct            sector exchange\n",
       "symbol                                                             \n",
       "A         0.123025  34.236838   2.376618     Capital Goods     nyse\n",
       "AA       -0.210734 -39.111751   5.697919  Basic Industries     nyse\n",
       "AAL      -0.580924 -62.886598   6.465470    Transportation   nasdaq\n",
       "AAN      -0.142530 -28.642169   5.012361        Technology     nyse\n",
       "AAON      0.179401  26.430863   3.699973     Capital Goods   nasdaq"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe with summary statistics\n",
    "pct_change_list = []\n",
    "delta_pct_list = []\n",
    "intra_pct_list = []\n",
    "sector_summ_list = []\n",
    "exchange_list = []\n",
    "for x in sym_delta.index:\n",
    "    pct_change_list.append(test_ind3.loc[x, 'pct_change'].mean())\n",
    "    delta_pct_list.append(test_ind3.loc[x, 'delta_pct'].mean())\n",
    "    intra_pct_list.append(test_ind3.loc[x, 'intra_pct'].mean())\n",
    "    sector_summ_list.append(close_df.loc[x, 'sector'][-1])\n",
    "    exchange_list.append(close_df.loc[x, 'exchange'][-1])\n",
    "summ_val = {'pct_change':pct_change_list, \\\n",
    "           'delta_pct':delta_pct_list, \\\n",
    "           'intra_pct':intra_pct_list, \\\n",
    "           'sector':sector_summ_list, \\\n",
    "           'exchange':exchange_list}\n",
    "summary_df = pd.DataFrame(summ_val, index=sym_delta.index)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a custom frequency by importing the Federal holidays\n",
    "#And adding/subtracting the stock exchange dates\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays(start=min(date_list), end=max(date_list))\n",
    "updated_holidays = list(holidays)\n",
    "updated_holidays.append(datetime(2020, 4, 10))\n",
    "updated_holidays = np.array(updated_holidays, dtype='datetime64[D]')\n",
    "updated_holidays = np.delete(updated_holidays, [0,9])\n",
    "bday_us = pd.offsets.CustomBusinessDay(holidays=updated_holidays)\n",
    "dt_index = pd.DatetimeIndex(date_list, freq=bday_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a quick list of sectors\n",
    "sector_list = list(test_ind3['sector'].unique())\n",
    "sector_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing sector averages in a dictionary\n",
    "date_dict = {}\n",
    "for x in sector_list:\n",
    "    temp_subset = test_ind3[test_ind3['sector'] == x]\n",
    "    dict_append = {}\n",
    "    for y in date_list:\n",
    "        temp_pct = []\n",
    "        temp_intra = []\n",
    "        temp_delta = []\n",
    "        for z in temp_subset.index:\n",
    "            if z[1] == y:\n",
    "                temp_pct.append(temp_subset.loc[z, 'pct_change'])\n",
    "                temp_intra.append(temp_subset.loc[z, 'intra_pct'])\n",
    "                temp_delta.append(temp_subset.loc[z, 'delta_pct'])\n",
    "        pct_mean = stats.mean(temp_pct)\n",
    "        intra_mean = stats.mean(temp_intra)\n",
    "        delta_mean = stats.mean(temp_delta)\n",
    "        dict_append[y] = [pct_mean, intra_mean, delta_mean]\n",
    "    date_dict[x] = dict_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new dataframe to hold sector averages\n",
    "sector_df = pd.DataFrame.from_dict({(i,j): date_dict[i][j] \n",
    "                           for i in date_dict.keys() \n",
    "                           for j in date_dict[i].keys()},\n",
    "                       orient='index', columns=['pct_change', 'intra_pct', 'delta_pct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary to split the tuple index\n",
    "sect_index = []\n",
    "date_index = []\n",
    "for x,y in sector_df.index:\n",
    "    sect_index.append(x)\n",
    "    date_index.append(y)\n",
    "index_dict = {'sector':sect_index, 'date':date_index}\n",
    "index_df = pd.DataFrame(index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>intra_pct</th>\n",
       "      <th>delta_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Basic Industries</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>-0.091392</td>\n",
       "      <td>3.308644</td>\n",
       "      <td>10.691496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>1.666739</td>\n",
       "      <td>3.289555</td>\n",
       "      <td>10.691496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04</th>\n",
       "      <td>0.140195</td>\n",
       "      <td>2.575912</td>\n",
       "      <td>10.691496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>0.315045</td>\n",
       "      <td>3.054165</td>\n",
       "      <td>10.691496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>0.148136</td>\n",
       "      <td>2.881368</td>\n",
       "      <td>10.691496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             pct_change  intra_pct  delta_pct\n",
       "sector           date                                        \n",
       "Basic Industries 2019-10-31   -0.091392   3.308644  10.691496\n",
       "                 2019-11-01    1.666739   3.289555  10.691496\n",
       "                 2019-11-04    0.140195   2.575912  10.691496\n",
       "                 2019-11-05    0.315045   3.054165  10.691496\n",
       "                 2019-11-06    0.148136   2.881368  10.691496"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting a multiindex for the sector_test dataframe\n",
    "sector_test = sector_df.copy().reset_index(drop=True)\n",
    "sector_test[['sector', 'date']] = index_df[['sector', 'date']]\n",
    "sector_test = sector_test.set_index(['sector', 'date'])\n",
    "new_index = pd.MultiIndex.from_tuples(sector_test.index, names=['sector', 'date'])\n",
    "sector_test.reindex(new_index)\n",
    "sector_test.sort_index(level=['sector','date'], ascending=True, inplace=True)\n",
    "sector_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a sector index\n",
    "sector_test['sector_avg'] = 0\n",
    "for x in sector_list:\n",
    "    temp_frame = sector_test.loc[x]\n",
    "    for y in temp_frame.index:\n",
    "        if y == temp_frame.index[0]:\n",
    "            sector_test.loc[(x,y), 'sector_avg'] = 100 \n",
    "        else: \n",
    "            sector_test.loc[(x,y), 'sector_avg'] = sector_test.loc[(x,prev), 'sector_avg'] \\\n",
    "            + sector_test.loc[(x,prev), 'sector_avg'] * temp_frame.loc[y, 'pct_change'] / 100\n",
    "        prev = y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 mo</th>\n",
       "      <th>2 mo</th>\n",
       "      <th>3 mo</th>\n",
       "      <th>6 mo</th>\n",
       "      <th>1 yr</th>\n",
       "      <th>2 yr</th>\n",
       "      <th>3 yr</th>\n",
       "      <th>5 yr</th>\n",
       "      <th>7 yr</th>\n",
       "      <th>10 yr</th>\n",
       "      <th>20 yr</th>\n",
       "      <th>30 yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1 mo  2 mo  3 mo  6 mo  1 yr  2 yr  3 yr  5 yr  7 yr  10 yr  \\\n",
       "date                                                                      \n",
       "2019-01-02  2.40  2.40  2.42  2.51  2.60  2.50  2.47  2.49  2.56   2.66   \n",
       "2019-01-03  2.42  2.42  2.41  2.47  2.50  2.39  2.35  2.37  2.44   2.56   \n",
       "2019-01-04  2.40  2.42  2.42  2.51  2.57  2.50  2.47  2.49  2.56   2.67   \n",
       "2019-01-07  2.42  2.42  2.45  2.54  2.58  2.53  2.51  2.53  2.60   2.70   \n",
       "2019-01-08  2.40  2.42  2.46  2.54  2.60  2.58  2.57  2.58  2.63   2.73   \n",
       "\n",
       "            20 yr  30 yr  \n",
       "date                      \n",
       "2019-01-02   2.83   2.97  \n",
       "2019-01-03   2.75   2.92  \n",
       "2019-01-04   2.83   2.98  \n",
       "2019-01-07   2.86   2.99  \n",
       "2019-01-08   2.88   3.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing yield data and combining it\n",
    "yield_2019 = pd.read_csv('yield2019.tsv', sep='\\t')\n",
    "yield_2020 = pd.read_csv('yield2020.tsv', sep='\\t')\n",
    "yield_comb = pd.concat([yield_2019, yield_2020], ignore_index=True)\n",
    "yield_comb.rename(str.lower, axis='columns', inplace=True)\n",
    "yield_comb['date'] = pd.to_datetime(yield_comb['date'], infer_datetime_format=True)\n",
    "yield_comb = yield_comb.set_index('date', drop=True)\n",
    "yield_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1mo</th>\n",
       "      <th>2mo</th>\n",
       "      <th>3mo</th>\n",
       "      <th>6mo</th>\n",
       "      <th>1yr</th>\n",
       "      <th>2yr</th>\n",
       "      <th>3yr</th>\n",
       "      <th>5yr</th>\n",
       "      <th>7yr</th>\n",
       "      <th>10yr</th>\n",
       "      <th>20yr</th>\n",
       "      <th>30yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1mo   2mo   3mo   6mo   1yr   2yr   3yr   5yr   7yr  10yr  20yr  \\\n",
       "date                                                                           \n",
       "2019-01-02  2.40  2.40  2.42  2.51  2.60  2.50  2.47  2.49  2.56  2.66  2.83   \n",
       "2019-01-03  2.42  2.42  2.41  2.47  2.50  2.39  2.35  2.37  2.44  2.56  2.75   \n",
       "2019-01-04  2.40  2.42  2.42  2.51  2.57  2.50  2.47  2.49  2.56  2.67  2.83   \n",
       "2019-01-07  2.42  2.42  2.45  2.54  2.58  2.53  2.51  2.53  2.60  2.70  2.86   \n",
       "2019-01-08  2.40  2.42  2.46  2.54  2.60  2.58  2.57  2.58  2.63  2.73  2.88   \n",
       "\n",
       "            30yr  \n",
       "date              \n",
       "2019-01-02  2.97  \n",
       "2019-01-03  2.92  \n",
       "2019-01-04  2.98  \n",
       "2019-01-07  2.99  \n",
       "2019-01-08  3.00  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing spacing from column names\n",
    "new_cols = {}\n",
    "for x in yield_comb.columns:\n",
    "    new_x = x.replace(\" \", \"\")\n",
    "    new_cols[x] = new_x\n",
    "yield_comb.rename(columns=new_cols, inplace=True)\n",
    "yield_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2037920cd48>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a quick example of some yield curves\n",
    "time_lengths = [1, 2, 3, 6, 12, 24, 36, 60, 84, 120, 240, 360]\n",
    "plt.plot(time_lengths, yield_comb.iloc[0])\n",
    "plt.plot(time_lengths, yield_comb.iloc[225])\n",
    "plt.plot(time_lengths, yield_comb.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1mo</th>\n",
       "      <th>2mo</th>\n",
       "      <th>3mo</th>\n",
       "      <th>6mo</th>\n",
       "      <th>1yr</th>\n",
       "      <th>2yr</th>\n",
       "      <th>3yr</th>\n",
       "      <th>5yr</th>\n",
       "      <th>7yr</th>\n",
       "      <th>10yr</th>\n",
       "      <th>20yr</th>\n",
       "      <th>30yr</th>\n",
       "      <th>10yr2yr</th>\n",
       "      <th>30yr5yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1mo   2mo   3mo   6mo   1yr   2yr   3yr   5yr   7yr  10yr  20yr  \\\n",
       "date                                                                           \n",
       "2019-01-02  2.40  2.40  2.42  2.51  2.60  2.50  2.47  2.49  2.56  2.66  2.83   \n",
       "2019-01-03  2.42  2.42  2.41  2.47  2.50  2.39  2.35  2.37  2.44  2.56  2.75   \n",
       "2019-01-04  2.40  2.42  2.42  2.51  2.57  2.50  2.47  2.49  2.56  2.67  2.83   \n",
       "2019-01-07  2.42  2.42  2.45  2.54  2.58  2.53  2.51  2.53  2.60  2.70  2.86   \n",
       "2019-01-08  2.40  2.42  2.46  2.54  2.60  2.58  2.57  2.58  2.63  2.73  2.88   \n",
       "\n",
       "            30yr  10yr2yr  30yr5yr  \n",
       "date                                \n",
       "2019-01-02  2.97     0.16     0.48  \n",
       "2019-01-03  2.92     0.17     0.55  \n",
       "2019-01-04  2.98     0.17     0.49  \n",
       "2019-01-07  2.99     0.17     0.46  \n",
       "2019-01-08  3.00     0.15     0.42  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_comb['10yr2yr'] = yield_comb['10yr'] - yield_comb['2yr']\n",
    "yield_comb['30yr5yr'] = yield_comb['30yr'] - yield_comb['5yr']\n",
    "yield_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping dates that fall outside my data range\n",
    "drop_dates = []\n",
    "for x in yield_comb.index:\n",
    "    if x > max(date_list):\n",
    "        drop_dates.append(x)\n",
    "    elif x < min(date_list):\n",
    "        drop_dates.append(x)\n",
    "yield_comb.drop(drop_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding yield columns to the sector_dates dataframe\n",
    "#Creating sector_values dataframe, contains the data for ARIMA\n",
    "sector_dates = sector_test.copy()\n",
    "sector_dates['10yr2yr'] = 0\n",
    "sector_dates['30yr5yr'] = 0\n",
    "for x in sector_list:\n",
    "    temp_frame = sector_dates.loc[x]\n",
    "    for y in temp_frame.index:\n",
    "        if y in yield_comb.index:\n",
    "            sector_dates.loc[(x,y),'10yr2yr'] = yield_comb.loc[y, '10yr2yr']\n",
    "            sector_dates.loc[(x,y),'30yr5yr'] = yield_comb.loc[y, '30yr5yr']\n",
    "        else: \n",
    "            sector_dates.loc[(x,y),'10yr2yr'] = yield_comb.loc[prev, '10yr2yr']\n",
    "            sector_dates.loc[(x,y),'30yr5yr'] = yield_comb.loc[prev, '30yr5yr']\n",
    "        prev = y\n",
    "sector_values = sector_test.drop(columns=['pct_change', 'intra_pct', 'delta_pct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "(Most of this is at the end with the interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Quick example of Box-Jenkins method, checking if data is stationary\n",
    "tech_test = sector_values.loc['Technology']\n",
    "tech_array = np.array(tech_test['sector_avg'])\n",
    "tech_series = pd.Series(np.diff(tech_array))\n",
    "# Graph data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,4))\n",
    "axes[0].plot(tech_test.index, tech_test['sector_avg'], '-')\n",
    "axes[0].set(title='Tech Stock Composite Index')\n",
    "\n",
    "# Differenced data\n",
    "axes[1].plot(tech_series.index, tech_series, '-')\n",
    "axes[1].hlines(0, 0, 250, 'r')\n",
    "axes[1].set(title='Tech Stock Composite - Differenced');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another example of Box-Jenkins, checking for AR\n",
    "#Becomes zero at lag p+1 on Partial Autocorrelation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,4))\n",
    "\n",
    "fig = sm.graphics.tsa.plot_acf(tech_series[1:], lags=40, ax=axes[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(tech_series[1:], lags=40, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Industries = ARIMA (1, 1, 1) : AIC Calculated = 907.3227725538518\n",
      "Capital Goods = ARIMA (1, 1, 1) : AIC Calculated = 908.2084706525967\n",
      "Consumer Durables = ARIMA (0, 1, 1) : AIC Calculated = 924.1129944473238\n",
      "Consumer Non-Durables = ARIMA (2, 1, 2) : AIC Calculated = 822.2465221229478\n",
      "Consumer Services = ARIMA (2, 1, 2) : AIC Calculated = 871.245340112939\n",
      "Energy = ARIMA (2, 1, 2) : AIC Calculated = 1001.8580297696692\n",
      "Finance = ARIMA (0, 1, 1) : AIC Calculated = 936.2001969115777\n",
      "Health Care = ARIMA (0, 1, 1) : AIC Calculated = 953.1109251511283\n",
      "Miscellaneous = ARIMA (2, 1, 3) : AIC Calculated = 917.9058810107442\n",
      "Public Utilities = ARIMA (0, 1, 0) : AIC Calculated = 832.6677642221832\n",
      "Technology = ARIMA (1, 1, 0) : AIC Calculated = 927.4112511482426\n",
      "Transportation = ARIMA (1, 1, 0) : AIC Calculated = 815.7548127933592\n"
     ]
    }
   ],
   "source": [
    "#Running all of the sector indices through auto_arima to find parameters\n",
    "#Also returning all of the prediction results at the same time\n",
    "order_dict = {}\n",
    "results_dict = {}\n",
    "pred_dict = {}\n",
    "for x in sector_list:    \n",
    "    temp_sector = sector_values.loc[x]\n",
    "    temp_sector.index.freq=bday_us\n",
    "    model = pm.auto_arima(temp_sector, max_p=8, max_d=4, max_q=8, seasonal=False, \\\n",
    "                          suppress_warnings=True, maxiter=200, error_action=\"ignore\")\n",
    "    model_dict = model.to_dict()\n",
    "    order_dict[x] = [model_dict[y] for y in ['order','aic']]\n",
    "    print(x +' = ARIMA {} : AIC Calculated = {}'.format(order_dict[x][0], order_dict[x][1]))\n",
    "    \n",
    "    results_dict[x] = model\n",
    "    pred = model.predict_in_sample(start=180, return_conf_int=True)\n",
    "    pred_vals = pred[0]\n",
    "    pred_conf = pred[1]\n",
    "    forecast = model.predict(5, return_conf_int=True)\n",
    "    forecast_vals = forecast[0]\n",
    "    forecast_conf = forecast[1]\n",
    "    pred_dict[x] = [pred_vals, pred_conf, forecast_vals, forecast_conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Industries\n",
      "The root mean squared error is 1.078.\n",
      "Capital Goods\n",
      "The root mean squared error is 1.092.\n",
      "Consumer Durables\n",
      "The root mean squared error is 1.142.\n",
      "Consumer Non-Durables\n",
      "The root mean squared error is 0.895.\n",
      "Consumer Services\n",
      "The root mean squared error is 1.003.\n",
      "Energy\n",
      "The root mean squared error is 1.333.\n",
      "Finance\n",
      "The root mean squared error is 1.062.\n",
      "Health Care\n",
      "The root mean squared error is 1.313.\n",
      "Miscellaneous\n",
      "The root mean squared error is 1.177.\n",
      "Public Utilities\n",
      "The root mean squared error is 0.755.\n",
      "Technology\n",
      "The root mean squared error is 1.333.\n",
      "Transportation\n",
      "The root mean squared error is 0.884.\n"
     ]
    }
   ],
   "source": [
    "#Creating a dataframe from the prediction dictionary\n",
    "#That was produced by the ARIMA outputs\n",
    "pred_df = pd.DataFrame.from_dict(pred_dict, orient='index', \\\n",
    "                                 columns=['pred_vals', 'pred_conf', 'forecast_vals', 'forecast_conf'])\n",
    "for x in sector_list:\n",
    "    test_values = sector_values.loc[x][180:]\n",
    "    sector_preds = pred_df.loc[x, 'pred_vals']\n",
    "    print(x), return_rmse(test_values,sector_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Basic Industries</th>\n",
       "      <th>Capital Goods</th>\n",
       "      <th>Consumer Durables</th>\n",
       "      <th>Consumer Non-Durables</th>\n",
       "      <th>Consumer Services</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Finance</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Miscellaneous</th>\n",
       "      <th>Public Utilities</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Transportation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>101.666739</td>\n",
       "      <td>101.275366</td>\n",
       "      <td>100.338850</td>\n",
       "      <td>100.464400</td>\n",
       "      <td>100.290714</td>\n",
       "      <td>101.805902</td>\n",
       "      <td>100.671028</td>\n",
       "      <td>101.329830</td>\n",
       "      <td>100.169585</td>\n",
       "      <td>100.154803</td>\n",
       "      <td>100.994993</td>\n",
       "      <td>101.137108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>101.809270</td>\n",
       "      <td>101.274496</td>\n",
       "      <td>100.327128</td>\n",
       "      <td>99.823490</td>\n",
       "      <td>100.138426</td>\n",
       "      <td>103.182333</td>\n",
       "      <td>100.714505</td>\n",
       "      <td>100.925657</td>\n",
       "      <td>100.129724</td>\n",
       "      <td>99.390808</td>\n",
       "      <td>100.770713</td>\n",
       "      <td>102.049915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>102.130015</td>\n",
       "      <td>101.263435</td>\n",
       "      <td>100.748291</td>\n",
       "      <td>99.857410</td>\n",
       "      <td>99.834400</td>\n",
       "      <td>102.658489</td>\n",
       "      <td>100.850102</td>\n",
       "      <td>100.348184</td>\n",
       "      <td>99.544895</td>\n",
       "      <td>98.767511</td>\n",
       "      <td>100.398887</td>\n",
       "      <td>102.377459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>102.281307</td>\n",
       "      <td>101.068357</td>\n",
       "      <td>100.415537</td>\n",
       "      <td>99.948731</td>\n",
       "      <td>99.673062</td>\n",
       "      <td>101.631083</td>\n",
       "      <td>100.930970</td>\n",
       "      <td>99.498252</td>\n",
       "      <td>99.472672</td>\n",
       "      <td>98.479397</td>\n",
       "      <td>99.844820</td>\n",
       "      <td>102.502214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Basic Industries  Capital Goods  Consumer Durables  \\\n",
       "0 2019-10-31        100.000000     100.000000         100.000000   \n",
       "1 2019-11-01        101.666739     101.275366         100.338850   \n",
       "2 2019-11-04        101.809270     101.274496         100.327128   \n",
       "3 2019-11-05        102.130015     101.263435         100.748291   \n",
       "4 2019-11-06        102.281307     101.068357         100.415537   \n",
       "\n",
       "   Consumer Non-Durables  Consumer Services      Energy     Finance  \\\n",
       "0             100.000000         100.000000  100.000000  100.000000   \n",
       "1             100.464400         100.290714  101.805902  100.671028   \n",
       "2              99.823490         100.138426  103.182333  100.714505   \n",
       "3              99.857410          99.834400  102.658489  100.850102   \n",
       "4              99.948731          99.673062  101.631083  100.930970   \n",
       "\n",
       "   Health Care  Miscellaneous  Public Utilities  Technology  Transportation  \n",
       "0   100.000000     100.000000        100.000000  100.000000      100.000000  \n",
       "1   101.329830     100.169585        100.154803  100.994993      101.137108  \n",
       "2   100.925657     100.129724         99.390808  100.770713      102.049915  \n",
       "3   100.348184      99.544895         98.767511  100.398887      102.377459  \n",
       "4    99.498252      99.472672         98.479397   99.844820      102.502214  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe that is easier to access later\n",
    "sectval_dict = {}\n",
    "for x in sector_list:\n",
    "    sectval_temp = sector_values.loc[x]\n",
    "    sectval_dict[x] = sectval_temp['sector_avg']\n",
    "sectval_df = pd.DataFrame(data=sectval_dict)\n",
    "sectval_df.reset_index(inplace=True)\n",
    "sectval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running stocks through the ARIMA model based on their sector\n",
    "stock_order_dict = {}\n",
    "stock_results_dict = {}\n",
    "stock_pred_dict = {}\n",
    "for x in sector_list:    \n",
    "    temp_sector = test_ind3[test_ind3['sector']==x]\n",
    "    sect_order = order_dict[x][0]\n",
    "    model = pm.ARIMA(order=sect_order, suppress_warnings=True)\n",
    "    for y in temp_sector.index.get_level_values(0).unique():\n",
    "        try:\n",
    "            temp_stock = temp_sector.loc[y]\n",
    "            temp_stock.index.freq=bday_us\n",
    "            model.fit(temp_stock['close'])\n",
    "            model_dict = model.to_dict()\n",
    "            stock_order_dict[y] = [model_dict[z] for z in ['order','aic']]\n",
    "\n",
    "            stock_results_dict[y] = model\n",
    "            pred = model.predict_in_sample(start=180, return_conf_int=True)\n",
    "            pred_vals = pred[0]\n",
    "            pred_conf = pred[1]\n",
    "            forecast = model.predict(5, return_conf_int=True)\n",
    "            forecast_vals = forecast[0]\n",
    "            forecast_conf = forecast[1]\n",
    "            stock_pred_dict[y] = [pred_vals, pred_conf,\\\n",
    "                                  forecast_vals, forecast_conf]\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAN</th>\n",
       "      <th>AAON</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABB</th>\n",
       "      <th>...</th>\n",
       "      <th>ZEN</th>\n",
       "      <th>ZG</th>\n",
       "      <th>ZI</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZLAB</th>\n",
       "      <th>ZM</th>\n",
       "      <th>ZNH</th>\n",
       "      <th>ZTO</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZYME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>20.790001</td>\n",
       "      <td>30.059999</td>\n",
       "      <td>74.930000</td>\n",
       "      <td>48.660000</td>\n",
       "      <td>162.479996</td>\n",
       "      <td>62.189999</td>\n",
       "      <td>29.360001</td>\n",
       "      <td>20.99</td>\n",
       "      <td>...</td>\n",
       "      <td>70.650002</td>\n",
       "      <td>32.389999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.470001</td>\n",
       "      <td>33.790001</td>\n",
       "      <td>69.889999</td>\n",
       "      <td>30.930000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>127.919998</td>\n",
       "      <td>34.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>76.970001</td>\n",
       "      <td>21.870001</td>\n",
       "      <td>30.559999</td>\n",
       "      <td>74.010002</td>\n",
       "      <td>49.110001</td>\n",
       "      <td>164.820007</td>\n",
       "      <td>63.955002</td>\n",
       "      <td>29.059999</td>\n",
       "      <td>21.17</td>\n",
       "      <td>...</td>\n",
       "      <td>72.230003</td>\n",
       "      <td>33.619999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.349998</td>\n",
       "      <td>35.590000</td>\n",
       "      <td>70.389999</td>\n",
       "      <td>31.070000</td>\n",
       "      <td>21.740000</td>\n",
       "      <td>125.339996</td>\n",
       "      <td>35.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>76.739998</td>\n",
       "      <td>22.910000</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>73.870003</td>\n",
       "      <td>49.610001</td>\n",
       "      <td>166.610001</td>\n",
       "      <td>64.375000</td>\n",
       "      <td>29.180000</td>\n",
       "      <td>21.58</td>\n",
       "      <td>...</td>\n",
       "      <td>71.959999</td>\n",
       "      <td>33.860001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.209999</td>\n",
       "      <td>35.980000</td>\n",
       "      <td>70.120003</td>\n",
       "      <td>32.779999</td>\n",
       "      <td>22.459999</td>\n",
       "      <td>124.760002</td>\n",
       "      <td>35.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>75.550003</td>\n",
       "      <td>22.590000</td>\n",
       "      <td>31.180000</td>\n",
       "      <td>65.459999</td>\n",
       "      <td>49.720001</td>\n",
       "      <td>168.139999</td>\n",
       "      <td>64.282501</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>21.58</td>\n",
       "      <td>...</td>\n",
       "      <td>70.709999</td>\n",
       "      <td>33.290001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.709999</td>\n",
       "      <td>36.790001</td>\n",
       "      <td>66.889999</td>\n",
       "      <td>33.590000</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>120.250000</td>\n",
       "      <td>36.189999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>75.790001</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>30.959999</td>\n",
       "      <td>62.320000</td>\n",
       "      <td>49.580002</td>\n",
       "      <td>169.699997</td>\n",
       "      <td>64.309998</td>\n",
       "      <td>29.620001</td>\n",
       "      <td>21.65</td>\n",
       "      <td>...</td>\n",
       "      <td>70.320000</td>\n",
       "      <td>33.610001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.369999</td>\n",
       "      <td>36.980000</td>\n",
       "      <td>66.830002</td>\n",
       "      <td>33.320000</td>\n",
       "      <td>22.170000</td>\n",
       "      <td>121.470001</td>\n",
       "      <td>35.009998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date          A         AA        AAL        AAN       AAON  \\\n",
       "0 2019-10-31  75.750000  20.790001  30.059999  74.930000  48.660000   \n",
       "1 2019-11-01  76.970001  21.870001  30.559999  74.010002  49.110001   \n",
       "2 2019-11-04  76.739998  22.910000  30.950001  73.870003  49.610001   \n",
       "3 2019-11-05  75.550003  22.590000  31.180000  65.459999  49.720001   \n",
       "4 2019-11-06  75.790001  21.900000  30.959999  62.320000  49.580002   \n",
       "\n",
       "          AAP       AAPL         AB    ABB  ...        ZEN         ZG  ZI  \\\n",
       "0  162.479996  62.189999  29.360001  20.99  ...  70.650002  32.389999 NaN   \n",
       "1  164.820007  63.955002  29.059999  21.17  ...  72.230003  33.619999 NaN   \n",
       "2  166.610001  64.375000  29.180000  21.58  ...  71.959999  33.860001 NaN   \n",
       "3  168.139999  64.282501  29.540001  21.58  ...  70.709999  33.290001 NaN   \n",
       "4  169.699997  64.309998  29.620001  21.65  ...  70.320000  33.610001 NaN   \n",
       "\n",
       "        ZION       ZLAB         ZM        ZNH        ZTO         ZTS  \\\n",
       "0  48.470001  33.790001  69.889999  30.930000  22.000000  127.919998   \n",
       "1  49.349998  35.590000  70.389999  31.070000  21.740000  125.339996   \n",
       "2  50.209999  35.980000  70.120003  32.779999  22.459999  124.760002   \n",
       "3  50.709999  36.790001  66.889999  33.590000  22.200001  120.250000   \n",
       "4  50.369999  36.980000  66.830002  33.320000  22.170000  121.470001   \n",
       "\n",
       "        ZYME  \n",
       "0  34.529999  \n",
       "1  35.009998  \n",
       "2  35.389999  \n",
       "3  36.189999  \n",
       "4  35.009998  \n",
       "\n",
       "[5 rows x 1479 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe that is easier to access later\n",
    "stock_pred_df = pd.DataFrame.from_dict(stock_pred_dict, orient='index', \\\n",
    "                                 columns=['pred_vals', 'pred_conf',\\\n",
    "                                          'forecast_vals', 'forecast_conf'])\n",
    "stockval_dict = {}\n",
    "for x in test_ind3.index.get_level_values(0).unique():\n",
    "    stockval_temp = test_ind3.loc[x]\n",
    "    stockval_dict[x] = stockval_temp['close']\n",
    "stockval_df = pd.DataFrame(data=stockval_dict)\n",
    "stockval_df.reset_index(inplace=True)\n",
    "stockval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2160\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0732\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0636\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0461\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0681\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0525\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0434\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0515\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0617\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0435\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0465\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0427\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0627\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0594\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0414\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0462\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0400\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0339\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0381\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0516\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0351\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0341\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0364\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0299\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0324\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0324\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0382\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0330\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0307\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0339\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0336\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0278\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0287\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0306\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0326\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0277\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0277\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0242\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0253\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0219\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0328\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0284\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0320\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0190\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0290\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0221\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0265\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0258\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0209\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0218\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0246\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0232\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0250\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0231\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0221\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0202\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0228\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0176\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0187\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0233\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0237\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0214\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0196\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0206\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0233\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0208\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0167\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0194\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0242\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0239\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0248\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0213\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0185\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0181\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0175\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0213\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0161\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0230\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0209\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203B9051948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0971\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0440\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0363\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0368\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0284\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0430\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0265\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0377\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0331\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0388\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0347\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0297\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0277\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0263\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0308\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0241\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0268\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0320\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0272\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0225\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0243\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0284\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0217\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0268\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0227\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0287\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0215\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0180\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0227\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0264\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0186\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0173\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0221\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0172\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0234\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0213\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0278\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0194\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0221\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0175\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0188\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0193\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0208\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0181\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0189\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0250\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0192\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0172\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0211\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0177\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0160\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0262\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0136\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0166\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0135\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0204\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0124\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0188\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0161\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0179\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0140\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0194\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0166\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0238\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0145\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0181\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0151\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0144\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0183\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0181\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0141\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0179\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0127\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0160\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0149\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0118\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0173\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0197\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0144\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203C405EF78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0840\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0454\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0335\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0315\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0380\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0301\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0288\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0277\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0255\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0242\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0230\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0209\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0206\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0342\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0216\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0193\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0219\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0235\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0192\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0231\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0188\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0233\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0168\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0235\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0189\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0196\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0176\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0178\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0143\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0191\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0194\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0178\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0189\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0188\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0178\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0157\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0193\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0159\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0200\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0154\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0154\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0169\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0152\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0131\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0170\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0144\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0143\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0190\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0122\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0144\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0153\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0157\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0154\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0137\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0121\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0131\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0156\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0149\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0186\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0129\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0145\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0152\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0129\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0140\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0103\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0120\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0135\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0146\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0142\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0119\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0161\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0104\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0151\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0116\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0113\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0144\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0119\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0137\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0122\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0119\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203B90514C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.2753\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0936\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0682\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0850\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0705\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0836\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0754\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0768\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0669\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0799\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0570\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0543\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0591\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0512\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0690\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0583\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0485\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0488\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0436\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0540\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0486\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0419\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0515\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0459\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0485\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0444\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0417\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0366\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0487\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0426\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0331\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0364\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0377\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0393\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0287\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0386\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0418\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0360\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0374\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0356\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0285\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0363\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0343\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0338\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0276\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0438\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0327\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0346\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0301\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.0319\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0370\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0297\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0316\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0255\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0300\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0319\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0290\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0268\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0305\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0270\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0274\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0258\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0254\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0328\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0283\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0215\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.0241\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0208\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0274\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0224\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.0246\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0188\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0237\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0266\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0205\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0216\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0208\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.0189\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0202\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020354119CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.2807\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0845\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0572\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0587\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0549\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0619\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0567\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0399\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0476\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0939\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0456\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0361\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0534\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0376\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0467\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0470\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0560\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0423\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0414\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0339\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0409\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0544\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0365\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0425\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0509\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0515\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0319\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0319\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0393\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0290\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0328\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0330\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0361\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0292\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0320\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0345\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0313\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0347\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0385\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0358\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0295\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0264\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0257\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0433\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0287\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0239\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0226\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0332\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0260\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0295\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0272\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0321\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0213\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0192\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0303\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0319\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0227\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0265\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0211\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0227\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0246\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0207\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0223\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0227\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0385\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0184\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0235\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0217\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0234\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0212\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0227\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0342\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0178\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0159\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0218\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0220\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0213\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0204\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0214\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0235\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203A6BC4DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.1405\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0701\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0616\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0431\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0457\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0407\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0418\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0405\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0532\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0335\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0473\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0284\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0286\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0483\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0351\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0311\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0289\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0295\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0312\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0319\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0292\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0333\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0245\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0274\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0301\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0324\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0224\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0281\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0294\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0273\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0240\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0302\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0297\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0223\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0206\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0202\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0217\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0275\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0221\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0208\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0233\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0179\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0200\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0207\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0216\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0217\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0197\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0219\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0186\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0194\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0171\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0154\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0169\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0158\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0160\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0186\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0163\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0135\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0164\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0196\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0152\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0207\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0142\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0182\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0175\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0107\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0163\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0146\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0131\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0193\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0132\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0155\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0128\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0139\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0191\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0127\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0184\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0127\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0118\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002038DB2A4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0517\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0244\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0159\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0190\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0197\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0204\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0214\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0176\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0168\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0163\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0224\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0179\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0151\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0156\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0172\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0148\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0149\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0133\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0149\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0148\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0168\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0172\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0193\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0146\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0130\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0159\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0143\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0129\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0139\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0123\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0129\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0111\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0134\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0115\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0115\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0145\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0140\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0134\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0111\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0124\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0108\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0130\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0092\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0114\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0097\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0109\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0128\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0105\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0092\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0102\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0095\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0082\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0107\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0095\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0099\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0095\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0097\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0111\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0103\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0099\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0096\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0087\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0071\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0098\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0094\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0085\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0081\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0098\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0079\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0091\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0094\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0093\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0085\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0074\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0092\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0078\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0077\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0102\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0078\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0085\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203C7186B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.1591\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0464\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0439\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0396\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0455\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0352\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0405\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0373\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0340\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0405\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0345\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0282\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0388\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0246\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0300\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0335\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0231\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0284\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0256\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0257\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0283\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0199\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0276\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0233\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0231\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0209\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0288\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0236\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0166\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0210\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0220\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0204\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0164\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0233\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0212\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0190\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0184\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0242\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0180\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0203\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0163\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0179\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0184\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0141\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0163\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0161\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0136\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0211\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0179\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0160\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0179\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0164\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0179\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0150\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0170\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0144\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0148\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0158\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0179\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0175\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0148\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0144\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0144\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0194\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0132\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0184\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0148\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0138\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0130\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0169\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0130\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0122\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0137\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0167\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0160\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0141\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0163\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0147\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0137\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0125\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203CF260288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.1628\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0527\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0541\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0631\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0459\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0467\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0434\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0506\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0542\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0455\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0351\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0457\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0311\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0353\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0389\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0380\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0288\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0380\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0473\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0322\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0296\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0310\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0262\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0303\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0263\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0279\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0268\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0313\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0221\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0231\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0267\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0231\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0207\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0304\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0186\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0203\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0227\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0295\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0160\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0186\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0209\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0167\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0192\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0233\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0148\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0233\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0170\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0160\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0227\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0202\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0186\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0187\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0133\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0187\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0176\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0212\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0181\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0181\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0206\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0166\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0145\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0166\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0165\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0172\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0235\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0118\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0176\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0132\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0151\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0202\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0140\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0142\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0127\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0115\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0216\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0135\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0184\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0122\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0168\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0146\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020354119828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0823\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0619\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0490\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0308\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0345\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0274\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0335\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0248\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0361\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0324\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0297\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0317\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0272\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0314\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0266\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0283\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0268\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0293\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0235\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0281\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0236\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0206\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0243\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0238\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0268\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0223\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0219\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0220\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0176\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0175\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0191\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0192\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0150\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0196\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0173\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0166\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0187\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0228\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0166\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0167\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0135\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0203\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0154\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0149\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0149\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0139\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0155\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0137\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0114\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0145\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0141\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0131\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0122\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0147\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0214\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0151\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0129\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0171\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0151\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0119\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0148\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0211\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0145\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0102\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0117\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0149\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0150\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0114\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0105\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0180\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0162\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0121\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0136\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0135\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0151\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0160\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0157\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0133\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0128\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0104\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002038DB2AE58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.1100\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0520\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0398\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0357\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0341\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0399\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0314\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0306\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0367\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0285\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0369\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0285\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0257\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0293\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0291\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0229\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0290\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0268\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0200\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0257\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0231\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0217\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0206\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0240\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0246\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0198\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0223\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0298\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0234\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0138\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0263\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0159\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0202\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0221\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0211\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0174\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0199\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0143\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0204\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0194\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0183\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0159\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0227\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0255\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0174\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0168\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0176\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0202\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0134\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0122\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0194\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0193\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0165\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0214\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0153\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0113\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0125\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0192\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0154\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0151\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0152\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0166\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0160\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0121\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0122\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0172\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0142\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0115\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0145\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0128\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0135\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0145\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0112\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0162\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0147\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0130\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0117\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0094\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0115\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0102\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203B2074A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.1582\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0541\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0589\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0621\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0588\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0459\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0467\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0431\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0559\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0442\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0432\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0413\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0532\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0439\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0365\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0308\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0352\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0305\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0383\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0258\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0281\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0403\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0327\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0268\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0309\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0231\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0363\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0339\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0242\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0234\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0257\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0354\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0227\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0293\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0218\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0240\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0275\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0230\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0288\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0214\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0210\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0254\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0264\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0227\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0229\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0270\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0211\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0231\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0253\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0192\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0217\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0189\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0206\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0203\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0216\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0207\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0176\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0203\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0215\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0177\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0156\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0184\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0184\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0198\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0191\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0177\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0162\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0209\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0179\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0205\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0157\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0191\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0204\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0163\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0161\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0170\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0173\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0177\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0152\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0198\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203CF285A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.1018\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0703\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0215\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0214\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0371\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0242\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0405\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0185\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0191\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0243\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0250\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0255\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0182\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0262\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0217\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0220\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0218\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0168\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0207\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0196\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0157\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0134\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0168\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0173\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0158\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0302\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0124\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0161\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0189\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0222\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0157\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0204\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0136\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0161\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0166\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0225\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0136\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0171\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0125\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0131\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0137\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0138\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0127\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0152\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0161\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0138\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0143\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0127\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0112\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0150\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0103\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0133\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0113\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0114\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0135\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0139\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0113\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0118\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0142\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0145\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0172\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0121\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0120\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0105\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0104\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0107\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0114\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0120\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0094\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0124\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0114\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0117\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0097\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0100\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0099\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0097\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0120\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.0102\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0111\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0106\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203C71DB5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.1534\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0700\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0691\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0719\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0561\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0452\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0423\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0379\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0385\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0389\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0574\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0375\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0465\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0369\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0336\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0517\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0413\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0372\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0342\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0353\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0275\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0405\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0297\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0384\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0307\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0287\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0317\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0284\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0284\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0262\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0312\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0300\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0359\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0246\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0275\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0352\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0244\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0380\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0238\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0246\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0305\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0208\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0191\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0264\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0227\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0303\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0236\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0214\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0196\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0209\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0246\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0232\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0215\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0263\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0214\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0205\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0227\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0194\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0210\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0220\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0195\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0194\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0204\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0200\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0238\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0188\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0190\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0259\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0180\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0214\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0190\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0177\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0171\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0235\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0178\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0194\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.0182\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0247\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0184\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0186\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203C1C9B828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.1142\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0361\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0274\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0232\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0272\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0309\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0280\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0248\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0289\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0264\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0237\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0217\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0275\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0237\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0208\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0279\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0178\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0209\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0269\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0201\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0175\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0217\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0246\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0251\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0202\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0154\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0224\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0162\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0200\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0181\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0199\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0212\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0193\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0184\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0166\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0160\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0174\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0196\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0159\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0183\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0178\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0190\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0175\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0150\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0155\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0167\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0175\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0171\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0164\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0134\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0167\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0147\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0185\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0180\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0148\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0153\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0158\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0143\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0142\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0169\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0128\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0142\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0165\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0165\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0138\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0119\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0160\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0127\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0133\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0137\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0130\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0135\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0114\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0171\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0095\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0170\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0131\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0115\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0126\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203DA769E58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.1015\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0508\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0552\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0480\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0394\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0511\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0468\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0261\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0279\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0298\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0359\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0280\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0263\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0255\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0231\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0311\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0230\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0196\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0154\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0189\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0252\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0194\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0208\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0170\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0184\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0173\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0193\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0192\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0145\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0193\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0188\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0125\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0130\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0208\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0163\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0125\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0189\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0124\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0157\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0186\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0213\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0137\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0134\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0138\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0159\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0164\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0180\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0134\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0199\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0151\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0153\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0117\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0157\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0135\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0166\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0137\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0117\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0116\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0142\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0136\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0132\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0183\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0162\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0136\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0145\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0133\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0115\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0103\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0125\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0124\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0114\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0122\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0133\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0142\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0109\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0102\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0128\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0170\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0135\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0113\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020343490798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.1015\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0375\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0416\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0386\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0405\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0371\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0280\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0455\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0263\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0425\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0277\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0274\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0263\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0227\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0264\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0314\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0160\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0316\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0190\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0208\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0181\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0247\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0184\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0207\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0148\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0202\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0138\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0184\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0190\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0177\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0174\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0134\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0163\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0124\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0183\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0170\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0141\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0189\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0173\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0228\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0148\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0156\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0125\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0147\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0114\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0163\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0108\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0116\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0109\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0141\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0117\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0135\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0149\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0107\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0170\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0090\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0118\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0130\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0108\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0167\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0103\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0121\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0088\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0113\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0131\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0117\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0155\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0106\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0119\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0120\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0121\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0088\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0099\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0132\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0103\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.0080\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0120\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0087\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0113\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203A25C5948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0584\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0250\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0186\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0191\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0197\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0186\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0154\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0160\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0193\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0151\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0173\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0182\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0104\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0153\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0175\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0172\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0121\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0118\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0122\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0188\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0129\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0130\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0129\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0159\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0119\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0139\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0116\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0135\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0156\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0133\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0122\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0136\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0135\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0108\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0137\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0113\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0144\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0115\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0133\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0159\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0107\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0106\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0106\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0162\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0110\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0096\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0111\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0142\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0095\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0106\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0127\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0106\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0119\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0124\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0121\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0095\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0106\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0125\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0111\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0108\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0101\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0109\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.0110\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0096\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0113\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0099\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0116\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0106\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0084\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0100\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0083\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0091\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0119\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0110\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0094\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0100\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0105\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0077\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0100\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0092\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002038DB2AE58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.2329\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0819\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0599\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0837\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0598\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0623\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0636\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0442\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0612\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0512\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0539\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0564\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0523\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0439\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0560\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0472\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0576\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0463\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0396\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0388\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0501\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0447\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0442\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0435\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0383\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0421\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0346\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0339\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0292\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0392\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0426\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0429\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0379\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0399\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0357\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0403\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0340\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0333\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0303\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0293\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0319\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0385\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0261\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0332\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0259\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0263\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0312\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0348\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0333\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0234\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0236\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0287\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0311\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0377\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0254\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0237\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0282\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0249\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0265\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0358\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0254\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0281\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0259\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0238\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0261\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0280\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0275\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0284\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0222\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0266\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0190\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0328\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0186\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0285\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0213\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0233\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0220\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0258\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203C9AB3D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.1163\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0315\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0329\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0305\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0307\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0430\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0246\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0219\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0427\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0294\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0280\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0340\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0265\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0255\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0314\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0328\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0236\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0250\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0341\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0233\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0271\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0293\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0279\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0224\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0219\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0275\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0246\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0214\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0261\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0238\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0210\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0241\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0269\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0201\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0227\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0253\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0188\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0187\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0185\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0275\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0219\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0201\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0215\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0187\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0176\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0199\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0166\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0183\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0175\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0175\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0197\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0197\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0132\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0165\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0161\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0151\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0217\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0148\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0157\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0178\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0171\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0190\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0189\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0149\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0157\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0167\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0186\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0154\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0167\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0164\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0153\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0136\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0164\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0154\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.0184\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0120\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0202\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0165\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0112\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203D4B8D5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.1410\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0533\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0640\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0524\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0431\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0475\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0494\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0444\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0442\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0352\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0474\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0397\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0402\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0427\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0437\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0362\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0324\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0274\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0287\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0392\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0341\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0282\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0238\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0338\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0389\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0242\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0322\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0397\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0313\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0280\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0226\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0312\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0262\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0265\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0240\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0334\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0240\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0271\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0249\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0280\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0245\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0194\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0211\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0203\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0307\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0186 0s - loss: 0.0\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0244\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0207\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0262\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0206\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0216\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0198\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0198\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0250\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0208\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0259\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0201\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0173\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0201\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0190\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0164\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0192\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0187\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0181\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0158\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0152\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0207\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0228\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0201\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0186\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0154\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0167\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0176\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0179\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0175\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0164\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0189\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0214\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0171\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203D958BCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0730\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0441\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0272\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0260\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0309\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0364\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0282\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0287\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0343\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0281\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0210\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0331\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0293\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0274\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0206\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0181\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0239\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0197\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0268\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0289\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0188\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0183\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0168\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0260\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0199\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0248\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0219\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0213\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0168 0s - loss: 0.01\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0160\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0218\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0135\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0173\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0187\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0149\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0143\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0146\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0124\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0159\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0188\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0151\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0155\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0151\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0156\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0151\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0122\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0144\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0162\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0130\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0143\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0134\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0125\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0179\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0147\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0160\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0149\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0178\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0145\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0180\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0108\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0133\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0139\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0115\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0121\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0159\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0128\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0122\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0139\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0109\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0136\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0109\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0109\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0132\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0107\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0123\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0142\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0125\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0111\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0118\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203E5CA63A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.1116\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0574\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0327\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0440\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0285\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0306\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0322\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0313\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0308\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0288\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0260\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0403\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0365\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0230\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0287\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0257\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0237\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0263\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0267\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0295\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0232\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0269\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0341\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0266 0s - loss: 0.026\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0224\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0244\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0224\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0262\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0223\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0265\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0216\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0239\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0173\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0204\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0192\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0176\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0154\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0209\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0215\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0196 0s - loss: 0.0\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0154\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0229\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0175\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0177\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0289\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0199\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0175 0s - loss: 0.0\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0195\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0154\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0171\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0157\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0148\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0202\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0151\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0178\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0245\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0168\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0163\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0210\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0151\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0195\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0161\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0183\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0151\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0175\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0172\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0171\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0148\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0169\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0149\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0187\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0156\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0148\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0183\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0148\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0161\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0159\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0158\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0130\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0133\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203C87D2318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0891\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0312\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0367\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0357\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0317\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0270\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0250\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0348\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0308\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0216\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0264\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0254\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0221\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0267\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0170\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0351\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0250\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0196\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0210\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0199\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0207\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0198\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0232\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0205\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0189\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0165\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0169\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0157\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0187\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0201\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0224\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0184\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0158\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0204\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0136\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0198\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0184\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0181\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0200\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0148\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0179\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0185\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0149\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0156\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0156\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0244\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0166\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0154\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0128\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0183\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0177\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0139\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0123 0s - loss: 0.012\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0193\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0178\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0161\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0129\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0119\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0141\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0148\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0183\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0119\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0127\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0189\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0156\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0136\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0169\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0151\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0158\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0149\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0130\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0136\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0161\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0126\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0137\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0145\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0121\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0137\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0131\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0119\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203DD81E438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.1497\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0420\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0606\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0383\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0426\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0298\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0462\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0330\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0417\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0258\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0489\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0304\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0328\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0324\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0307\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0414\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0422\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0270\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0324\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0428\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0301\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0273\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0314\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0255\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0329\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0354\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0282\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0279\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0213\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0319\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0291\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0270\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0273\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0252\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0286\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0288\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0287\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0226\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0218\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0262 0s - loss: 0.026\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0235\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0219\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0367\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0210\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0281\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0335\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0242\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0240\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0286\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0278\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0264\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0239\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0248\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0273\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0294\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0196\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0329\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0234\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0247\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0302\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0261\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0220 0s - loss: 0.0\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0226\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0283\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0291\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0269\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0213\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0230\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0212\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0227\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0203\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0264\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0269\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0204\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0261\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0208\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0242\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0216\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0209\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0220\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203A6C305E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0801 0s - loss: 0.1\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0426\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0256\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0211\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0232\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0271\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0215\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0299\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0213\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0150\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0194\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0194\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0150\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0208\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0148\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0189\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0155\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0203\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0156\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0153\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0149\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0171\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0135\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0172\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0197\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0114\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0134\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0104\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0130\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0134\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0164\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0105\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0128\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0148\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0105\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0120\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0125\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0120\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0128\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0119\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0103\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0101\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0116\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0111\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0100\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0127\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0100\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0109\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0137\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0090\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0100\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0079\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0087\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0093\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0078\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0111\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0097\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0103\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0093\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0096\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0078\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0112\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0089\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0071\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0112\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0096\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0086\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0090\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0103\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0100\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0093\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0068\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0077\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0104\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0083\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0094\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0069\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0104\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0056\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0083\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203DA661D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.1209\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0441\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0317\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0291\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0194\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0252\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0217\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0203\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0360\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0325\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.0189\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0183\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0188 0s - loss: 0.018\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0204\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0235\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0277\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0252\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0154\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0190\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0180\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0214\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0168\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0199\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0195\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0210\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0224\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0251\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0197\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0153\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0152\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0207\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0223\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0134\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0169\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0189\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0193\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0229\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0112\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0251\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0122\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0238\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0165\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0142\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0135\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0120\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0150\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0131\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0160\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0138\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0126\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0135\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0161\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0129\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0147\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0156\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0193\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0122\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0191\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0161\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0134\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0133\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0107\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0125\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0143\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0099\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0120\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0125\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0106\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0160\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0118\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0137\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0115\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0110\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0122\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0161\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0153\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0113\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0145\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0200\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203E15535E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.2082\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0553\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0457\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0538\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0568\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0459\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0440\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0399\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0634\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0496\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0425\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0490\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0354\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0418\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0367\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0382\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0433\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0375\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0317\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0354\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0326\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0341\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0397\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0336\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0333\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0396\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0272\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0397\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0327\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0379\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0323\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0303\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0266\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0295\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0351\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0253\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0260\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0257\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0280\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0230\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0261\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0293\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0298\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0239\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0189\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0272\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0256\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.0259\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0313\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0211\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0211\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0218\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0262\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0255\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0277\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0286\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0242\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0242\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0246\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0218\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0271\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0230\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0197\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0241\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0179\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0195\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0313\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0235\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0191\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0202\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0208\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0202\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0221\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0202\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0200\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0266\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0224\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0181\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0239\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203E4A9ACA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0996\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0393\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0410\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0383\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0315\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0424\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0376\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0317\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0376\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0315\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0296\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0272\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0219\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0210\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0334\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0208\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0213\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0211\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0207\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0249\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0244\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0204\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0138\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0201\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0204\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0245\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0235\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0169\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0224\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0174\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0132\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0176\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0180\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0177\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0246\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0169\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0140\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0203\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0141\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0168\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0207\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0152\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0183\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0143\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0143\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0174\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0148\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0221\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0145\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0166\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0162\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0155\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0149\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0157\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0135\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0141\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0138\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0159\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0096\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0142\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0167\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0138\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0147\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0126\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0116\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0157\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0098\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0152\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0137\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0143\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0124\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0132\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0130\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0128\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0107\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0169\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0111\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0103\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020395D973A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.1771\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0474\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0365\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0396\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0407\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0406\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0433\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0596\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0353\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0380\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0364\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0252\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0369\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0314\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0452\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0305\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0252\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0294\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0322\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0419\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0247\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0298\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0253\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0355\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0291\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0303\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0227\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0297\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0240\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0292\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0206\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0243\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0359\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0234\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0248\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0205\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0231\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0187\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0224\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0218\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0200\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0205\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0244\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0213\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0238\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0191\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0217\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0249\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0213\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0160\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0177\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0163\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0184\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0157\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0191\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0233\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0186\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0176\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0192\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0151\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0164\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0191\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0190\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0172\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0159\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0149\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0181\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0148\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0153\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0169\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0198\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0175 0s - loss: 0.01\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0226\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0144\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0149\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0140\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0155\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0140\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0156\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203A7FCB9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.1167 0s - loss: 0.116\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0406\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0411\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0430\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0358\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0399\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0267\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0365\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0230\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0216\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0286\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0290\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0324\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0234\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0263\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0218\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0304\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0159\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0153\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0173\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0251\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0242\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0159\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0244\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0178\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0292\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0202\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0168\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0160\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0161\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0199\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0154\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0167\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0142\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0181\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0182\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0213\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0178\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0210\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0148\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0173\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0136\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0142\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0154\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0112\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0331\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0161\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0124\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0156\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0145\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0134\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0184\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0134\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0146\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0174\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0166\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0117\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0114\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0152\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0131\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0126\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0173\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0110\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0129\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0128\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0127\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0123\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0117\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0135\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0113\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0134\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0199\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0139\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0145\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0131\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0123\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0096\n",
      "Epoch 78/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0116\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0144\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0116\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203EA30A8B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.1355\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0739\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0513\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0415\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0345\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0232\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0323\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0364\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0497\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0294\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0275\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0266\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0250\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0213\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0205\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0328\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0214\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0302\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0224\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0364\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0191\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0332\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0286\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0205\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0248\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0259\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0254\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0173\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0212\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0209\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0189\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0269\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0243\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0186\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0212\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0176\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0211\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0188\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0171\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0237\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0185\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0154\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0216\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0129\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0213\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0166\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0160\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0192\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0146\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0174\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0159\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0240\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0180\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0130\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0120\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0204\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0188\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0124\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0136\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0243\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0164\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0130\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0165\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0129\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0127\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0110\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0203\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0213\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0106\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0126\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0126\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0153\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0151\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0126\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0165\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0134\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0133\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0149\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0123\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0130\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203A261BB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 164ms/step - loss: 0.2177\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0799\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0652\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0686\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0555\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0496\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0639\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0454\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0308\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0565\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0313\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0251\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0495\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0382\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0380\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0289\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0380\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0341\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0297\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0301\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0285\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0265\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0356\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0330\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0272\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0287\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0291\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0228\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0245\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0245\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0222\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0294\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0235\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0206\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0286\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0269\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0164\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0231\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0211\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0199\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0262\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0219\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0227\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0285\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0221\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0191\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0196\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0222\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0203\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0211\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0187\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0156\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0185\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0163\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0183\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0237\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0266\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0175\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0165\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0159\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0200\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0215\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0186\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0249\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0141\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0147\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0156\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0168\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0181\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0181\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0223\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0144\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0161\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0170\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0159\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0184\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0201\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0212\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0140\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0156\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002037F3ADC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2169\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0706\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0659\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0500\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0583\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0725\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0446\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0574\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0557\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0524\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0641\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0619\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0465\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0584\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0429\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0428\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0360\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0635\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0558\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0378\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0401\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0431\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0463\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0507\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0408\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0402\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0357\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0383\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0461\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0340\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0534\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0374\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0334\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0331\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0434\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0396\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0314\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0346\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0389\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0317\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0305\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0471\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0320\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0308\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0283\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0382\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0295\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0286\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0327\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0343\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0263\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0358\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0322\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0282\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0307\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0244\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0356\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0275\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0308\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0300\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0334\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0267\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0283\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0268\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0260\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0324\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0319\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0258\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0265\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0274\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0272\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0261\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0310\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0277\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0233\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0333\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0236\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0273\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0317\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0217\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203EB96AA68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2672\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0607\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0651\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0744\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0560\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0588\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0611\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0443\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0585\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0582\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0498\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0467\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0587\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0495\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0503\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0422\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0618\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0453\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0380\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0435\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0411\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0378\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0338\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0369\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0429\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0346\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0326\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0348\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0371\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0384\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0362\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0395\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0257\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0293\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0401\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0299\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0377\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0301\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0230\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0313\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0211\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0291\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0258\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0368\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0297\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0271\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0226\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0254\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0319\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0284\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0179\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0274\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0229\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0276\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0213\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0246\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0283\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0241\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0315\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0226\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0227\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0205\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0163\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0220\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0231\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0232\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0235\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0171\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0182\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0260\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0258\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0175\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0211\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0202\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0198\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0206\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0196\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0172\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0166\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0157\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020395BEB828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.1310\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0440\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0410\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0534\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0426\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0447\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0425\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0327\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0406\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0349\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0408\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0434\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0284\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0320\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0410\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0361\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0296\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0376\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0282\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0355\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0285\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0311\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0367\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0267\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0296\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0307\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0288\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0284 0s - loss: 0.0\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0261\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0294\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0236\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0267\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0305\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0261\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0209\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0249\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0275\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0232\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0204\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0272\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0204\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0222\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0220\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0255\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0212\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0247\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0258\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0228\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0207\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0237\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0190\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0194\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0191\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0242\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0192\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0178\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0204\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0210\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0179\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0185\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0180\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0215\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0176\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0235\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0231\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0187\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0173\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0199\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0194\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0224\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0186\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0181\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0203\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0200\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0212\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0160\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0165\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0184\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0141\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203FCEA8D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0904\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0365\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0317\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0334\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0276\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0325\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0268\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0241\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0266\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0332\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0192\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0335\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0184\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0167\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0197\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0207\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0209\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0212\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0202\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0151\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0256\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0152\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0223\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0170\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0229\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0158\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0191\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0143\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0199\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0133\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0142\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0166\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0148\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0136\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0210\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0168\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0145\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0124\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0228\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0226\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0159\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0135\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0154\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0183\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0141\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0146\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0129\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0141\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0167\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0175\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0126\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0098\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0138\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0145\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0101\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0134\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0193\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0104\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0149\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0128\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0179\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0119\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0131\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0123\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0114\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0135\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0113\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0157\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0106\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0140\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0110\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0114\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0120\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0092\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0124\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0136\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0116\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0128\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0109\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020406F375E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.1648\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0667\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0637\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0624\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0549\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0584\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0446\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0808\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0449\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0384\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0423\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0402\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0462\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0361\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0460\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0424\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0388\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0427\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0348\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0409\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0308\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0320\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0401\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0394\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0275\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0461\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0419\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0307\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0285\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0322\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0295\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0315\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0325\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0240\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0295\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0331\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0224\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0280\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0297\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0263\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0249\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0303\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0285\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0211\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0248\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0227\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0234\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0217\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0211\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0311\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0272\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0217\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0212\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0225\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0199\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0213\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0287\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0197\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0201\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0191\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0197\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0255\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0178\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0192\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0184\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0182\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0226\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0171\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0200\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0238\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0177\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0154\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0199\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0154\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0231\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0171\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0179\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0198\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203EA3C2DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.1828\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0675\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0570\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0545\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0579\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0610\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0516\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0590\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0558\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0399\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0422\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0538\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0454\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0403\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0423\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0545\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0347\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0337\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0431\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0373\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0361\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0479\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0333\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0342\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0418\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0327\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0331\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0322\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0375\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0349\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0337\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0294\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0318\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0314\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0337\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0301\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0250\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0393\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0248\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0253\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0259\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0336\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0235\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0347\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0218\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0302\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0254\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0281\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0246\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0326\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0229\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0215\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0335\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0229\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0246\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0215\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0272\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0228\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0240\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0211\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0190\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0257\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0237\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0295\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0220\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0217\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0171\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0205\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0319\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0197\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0191\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0247\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0232\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0235\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0250\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0173\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0183\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0205\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0240\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203D71F6F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.1982\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0556\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0500\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0542\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0435\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0547\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0420\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0406\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0559\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0491\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0364\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0363\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0342\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0522\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0368\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0406\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0337\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0340\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0328\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0351\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0339\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0337\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0345\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0451\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0346\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0293\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0259\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0264\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0413\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0257\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0408\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0284\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0376\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0290\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0253\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0223\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0233\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0300\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0291\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0269\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0214\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0275\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0294\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0253\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0213\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0225\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0277\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0236\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0269\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0203\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0241\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0279\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0208\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0213\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0265\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0236\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0236\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0231\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0185\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0191\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0197\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0251\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0246\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0229\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0187\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0232\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0212\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0219\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0154\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0177\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0196\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0219\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0208\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0199\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0184\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0236\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0240\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0171\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0192\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0161\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203DFE85CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0885\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0400\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0364\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0295\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0297\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0341\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0262\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0251\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0340\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0247\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0315\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0223\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0274\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0291\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0216\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0234\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0203 0s - loss: 0.0\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0185\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0196\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0231\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0193\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0299\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0175\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0171\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0200\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0163\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0153\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0210\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0233\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0164\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0170\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0201\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0140\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0184\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0165\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0165\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0198\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0153\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0141\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0179\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0139\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0226\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0181\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0155\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0141\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0169\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0141\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0158\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0157\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0191\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0146\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0124\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0174\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0119\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0143\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0135\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0098\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0143\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0203\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0158\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0142\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0103\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0134\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0100\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0125\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0136\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0123\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0109\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0119\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0124\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0114\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0118\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0137\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0151\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0136\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0123\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0109\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0115\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0105\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0119\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203BE6D1798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.1189\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0413\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0405\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0383\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0336\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0420\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0393\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0378\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0263\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0256\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0288\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0271\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0250\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0322\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0228\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0184\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0283\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0297\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0225\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0226\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0223\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0232\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0290\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0235\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0182\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0188\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0214\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0233\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0224\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0193\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0155\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0221\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0162\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0164\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0159\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0151\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0232\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0145\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0169\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0160\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0174\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0189\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0140\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0176\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0154\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0189\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0152\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0164\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0144\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0173\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0151\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0136\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0187\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0124\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0173\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0111\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0153\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0164\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0160\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0171\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0159\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0151\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0130\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0117\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0166\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0127\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0146\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0127\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0106\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0170\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0121\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0158\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0111\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0119\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0124\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0106\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0162\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0118\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0122\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203FBBC2B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0909\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0330\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0289\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0339\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0260\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0254\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0221\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0258\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0286\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0228\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0389\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0237\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0274\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0261\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0298\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0223\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0244\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0261\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0202\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0213\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0262\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0228\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0231\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0262\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0196\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0197\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0244\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0209\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0214\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0178\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0202\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0198\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0191\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0178\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0235\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0201\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0167\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0202\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0198\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0130\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0176\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0179\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0189\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0227\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0160\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0146\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0172\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0155\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0148\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0127\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0171\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0181\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0181\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0140\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0152\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0123\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0235\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0140\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0140\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0119\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0146\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0158\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0124\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0165\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0130\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0143\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0129\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0130\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0135\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0135\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0150\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0160\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0124\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0139\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0112\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0140\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0120\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0129\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0108\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0116\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002040B32D288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0812\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0418\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0284\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0365\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0366\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0281\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0274\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0329\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0260\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0307\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0271\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0271\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0299\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0243\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0241\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0256\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0207\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0321\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0288\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0229\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0201\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0220\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0209\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0273\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0204\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0243\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0224\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0189\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0222\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0216\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0261\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0208\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0192\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0216\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0183\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0188\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0177\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0227\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0180\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0185\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0204\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0194\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0165\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0207\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0161\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0187\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0208\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0175\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0200\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0201\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0167\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0162\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0159\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0189\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0165\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0202\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0194\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0189\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0182\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0181\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0200\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0121\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0205\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0182\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0186\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0156\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0159\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0152\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0154\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0163\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0160\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0174\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.0189\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0158\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0174\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0141\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0157\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0136\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0156\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0164\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204133F1948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.1936\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0618\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0621\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0739\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0504\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0599\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0495\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0578\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0509\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0573\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0431\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0499\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0556\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0504\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0481\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0455\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0495\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0404\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0472\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0385\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0365\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0401\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0448\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0320\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0399\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0333\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0379\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0349\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0341\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0317\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0314\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0378\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0355\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0329\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0324\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0405\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0324\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0346\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0383\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0296\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0385\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0377\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0383\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0360\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0362\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0341\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0322\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0331\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0286\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0279\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0300\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0297\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0339\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0313\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0347\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0254\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0299\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0296\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0274\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0345\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0304\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0378\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0297\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0334\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0308\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0315\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0276\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0285\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0293\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0352\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0281\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0276\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0276\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0279\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0293\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0313\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0268\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0305\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.0257\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0319\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002041D42BEE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0929\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0391\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0411\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0354\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0270\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0260\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0209\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0319\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0230\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0267\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0249\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0246\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0197\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0158\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0325\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0173\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0223\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0176\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0188\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0174\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0147\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0159\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0225\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0230\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0198\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0152\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0153\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0187\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0143\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0155\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0164\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0134\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0179\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0193\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0118\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0180\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0137\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0142\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0157\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0124\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0125\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0135\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0153\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0150\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0128\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0128\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0131\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0144\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0126\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0111\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0140\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0132\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0113\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0159\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0119\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0139\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0123\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0115\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0110\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0145\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0111\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0091\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0106\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0097\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0168\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0125\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0113\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0117\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0105\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0122\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0102\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0147\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0094\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0108\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0135\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0115\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0096\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0120\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0088\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0098\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203DA7AA678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1032\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0367\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0456\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0345\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0355\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0385\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0541\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0431\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0372\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0391\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0434\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0404\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0302\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0358\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0327\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0286\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0377\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0425\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0346\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0273\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0201\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0363\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0271\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0410\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0284\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0319\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0244\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0211\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0259\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0337\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0280\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0199\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0307\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0228\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0188\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0236\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0263\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0241\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0187\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0201\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0215\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0226\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0190\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.0199\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0294\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0195\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0181\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0121\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0182\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0208\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0175\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0239\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0218\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0144\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0219\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0172\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0152\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0190\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0167\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0165\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0179\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0184\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0145\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0216\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0156\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0190\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0132\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0128\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0132\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0144\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0156\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0174\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0204\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0127\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0194\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0219\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0144\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0176\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0124\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0199\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002040DB06438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1388\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0691\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0423\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0468\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0535\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0356\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0525\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0420\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0452\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0400\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0353\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0339\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0476\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0291\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0361\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0391\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0398\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0319\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0354\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0305\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0241\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0283\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0268\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0300\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0350\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0278\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0365\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0281\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0284\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0229\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0207\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0260\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0325\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0257\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0277\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0279\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0239\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0271\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0285\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0262\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0226\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0272\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0268\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0289\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0267\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0245\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0225\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0254\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0225\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0248\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0230\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0244\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0212\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0190\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0206\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0241\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0214\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0196\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0251\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0252\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0195\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0203\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0223\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0199\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0170\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0186\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0243\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0223\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0202\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0183\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0202\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0223\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0213\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0168\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0180\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0170\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0187\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0218\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0176\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0211\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020343490D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1967\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0488\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0548\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0477\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0424\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0606\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0412\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0483\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0466\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0593\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0520\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0357\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0439\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0447\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0457\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0438\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0582\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0292\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0319\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0463\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0352\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0392\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0274\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0389\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0265\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0312\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0457\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0290\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0248\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0430\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0326\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0340\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0320\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0283\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0332\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0329\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0270\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0323\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0345\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0251\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0253\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0355\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0329\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0263\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0252\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0365\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0266\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0242\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0323\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0311\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0258\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0202\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0244\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0424\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0235\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0218\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0300\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0209\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0228\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0316\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0254\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0176\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0244\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0247\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0278\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0223\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0205\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0247\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0299\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0175\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0244\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0192\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0172\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0251\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0228\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0217\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0182\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0222\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0207\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0259\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020352ED8AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.1035\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0343\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0411\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0366\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0330\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0303\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0248\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0323\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0275\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0275\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0299\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0273\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0188\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0234\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0230\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0309\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0201\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 0.0197\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0252\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0174\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0179\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0174\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0245\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0157\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0128\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0194\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0166\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0147\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0150\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0180\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0134\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0161\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0150\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0130\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0138\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0122\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0164\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0144\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0113\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0131\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0120\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0112\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0137\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0096\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0131\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0092\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0106\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0132\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0088\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0135\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0106\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0119\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0087\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0121\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0084\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0106\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0113\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0111\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0099\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0099\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0113\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0084\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0129\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0076\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0050\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0096\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0098\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0089\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0062\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0086\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0107\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0072\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0096\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0089\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0075\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0098\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0073\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0118\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0091\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204026EA828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.2113\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0558\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0500\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0583\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0531\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0534\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0411\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0480\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0341\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0455\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0332\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0401\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0353\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0409\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0410\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0297\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0363\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0380\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0263\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0368\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0288\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0334\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0283\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0267\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0325\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0350\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0247\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0314\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0241\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0261\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0301\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0280\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0222\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0211\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0203\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0250\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0229\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0304\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0204\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0200\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0246\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0207\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0211\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0230\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0200\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0161\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0181\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0197\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0255\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0196\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0204\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0165\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0175\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0188\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0199\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0208\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0220\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0165\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0148\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0173\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0212\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0183\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0201\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0195\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0184\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0139\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0151\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0248\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0169\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0153\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0176\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0161\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0125\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0156\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0148\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0175\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0149\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0176\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0183\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002040A05BD38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.2014\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0700\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0682\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0758\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0565\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0427\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0603\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0491\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0543\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0438\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0422\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0608\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0416\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0556\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0385\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0469\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0329\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0310\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0470\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0364\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0416\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0382\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0290\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0345\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0406\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0318\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0328\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0332\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0249\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0354\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0264\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0300\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0323\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0343\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0316\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0290\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0282\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0256\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0325\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0230\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0266\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0239\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0225\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0295\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0285\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0220\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0222\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0211\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0234\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0253\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0250\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0204\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0229\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0215\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0296\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0238\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0202\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0195\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0190\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0208\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0202\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0282\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0227\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0208\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0208\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0216\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0157\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0238\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0286\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0207\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0182\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0169\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 0.0204\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0213\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0186\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0211\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0171\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0195\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0195\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0218\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020405D005E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.1561\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0580\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0631\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0507\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0450\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0438\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0404\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0532\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0537\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.0359\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0373\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.0455\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0347\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0319\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0352\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0485\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0299\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.0424\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.0305\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0310\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0324\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0299\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0343\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0305\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0297\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0258\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0346\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0245\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0240\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0243\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0251\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0266\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0288\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0244\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0263\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0225\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0241\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0309\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0242\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0223\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0225\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0247\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0187\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0298\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0215\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0207\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0209\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0286\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0166\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0200\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0191\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0252\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0156\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0187\n",
      "Epoch 55/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0181\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0204\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0201\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0255\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0162\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0213\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0129\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0169\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0239\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0158\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0143\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0214\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0162\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0161\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0179\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0160\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0202\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0145\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0207\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0185\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0162\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0155\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0154\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0171\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0148\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020421F16CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.1546\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0377\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0471\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0490\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0447\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0438\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0374\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0406\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0371\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0312\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0464\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0309\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0311\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0297\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0323\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0284\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0387\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0294\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0263\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0248\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0347\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0312\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0247\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0363\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0269\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0270\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0223\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0266\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0315\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0227\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0251\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0208\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0317\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0199\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0279\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0293\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0199\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0266\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0200\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0228\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0245\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0236\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0238\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0188\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0191\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0216\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0200\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0271\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0182\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0177\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0181\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0203\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0180\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0164\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0230\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0145\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0161\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0187\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0183\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0152\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0173\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0222\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0148\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0150\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0228\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0129\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0163\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0196\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0179\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0147\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0163\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0108\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0207\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0099\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0146\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0181\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0147\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 0.0124\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0119\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002037F3AD438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.1615\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0467\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0457\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0516\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0493\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0521\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0421\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0503\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0452\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0405\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0362\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0353\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0371\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0439\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0276\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0325\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0395\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0267\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0316\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0330\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0245\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0256\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0256\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0288\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0321\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0318\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0213\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0246\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0211\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0253\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0228\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0247\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0229\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0172\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0269\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0220\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0220\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0283\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0161\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0226\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0292\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0210\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0234\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0248\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0162\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0212\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0236\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0221\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0221\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0209\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0193\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0218\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0195\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0217\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0197\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0182\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0192\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0177\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0165\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0209\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0213\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0203\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0154\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0219\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0167\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0213\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0161\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0234\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0165\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0146\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0159\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0209\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0203\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0207\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0222\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0174\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0181\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0149\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0175\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0181\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020424111678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0860\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0330\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0312\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0315\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0298\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0341\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0276\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0267\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0368\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0347\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0263\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0234\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0216\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0302\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0298\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0227\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0233\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0213\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0307\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0199\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0161\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0203\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0226\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0185\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0195\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0191\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0189\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0216\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0187\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0158\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0173\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0211\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0186\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0198\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0163\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0187\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0154\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0163\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0116\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0184\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0154\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0172\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0126\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0157\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0150\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0182\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0124\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0128\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0146\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0113\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0163\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0140\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0120\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0129\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0105\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0131\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0090\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0108\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0146\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0115\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0081\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0084\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0147\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0101\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0137\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0123\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0104\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0121\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0096\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0136\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0105\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0105\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0111\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0092\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0134\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0095\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0115\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0108\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0081\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0125\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002039CA72CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.1383\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0594\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0511\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0536\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0455\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0433\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0454\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0357\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0396\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0348\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0340\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0349\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0361\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0351\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0313\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0384\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0320\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0290\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0260\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0309\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0340\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0302\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0291\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0320\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0300\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0258\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0285\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0272\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0268\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0222\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0204\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0253\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0188\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0208\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0261\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0208\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0261\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0193\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0204\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0201\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0186\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0209\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0172\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0190\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0247\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0198\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0201\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0158\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0132\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0200\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0158\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0222\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0201\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0127\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0199\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0164\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0158\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0144\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0173\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0129\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0163\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0144\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0264\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0121\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0127\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0136\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0117\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0171\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0120\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0158\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0132\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0144\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0145\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0119\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0181\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0147\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0156\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0113\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0111\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203FBC998B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0869\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0359\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0334\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0346\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0281\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0268\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0348\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0251\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0301\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0323\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0259\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0212\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0337\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0225\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0252\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0268\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0204\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0235\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0251\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0257\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0263\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0231\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0188\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0186\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0240\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0205\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0252\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0185\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0230\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0239\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0195\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0215\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0188\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0167\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0186\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0217\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0198\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0211\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0180\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0147\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0176\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0183\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0133\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0179\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0135\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0164\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0204\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0133\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0129\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0167\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0178\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0184\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0156\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0165\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0134\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0128\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0197\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0138\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0165\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0121\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0165\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0166\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0142\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0101\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0126\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0136\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0149\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0140\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0126\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0147\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0159\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0111\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0145\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0128\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0144\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0146\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0128\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0117\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0139\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0133\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203FBBEECA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.2535\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0824\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0673\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0661\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0631\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0754\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0490\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0538\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0906\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0600\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0426\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0485\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0477\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0503\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0504\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0419\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0462\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0591\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0333\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.0457\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0335\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0400\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0442\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0379\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0502\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0402\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0389\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0409\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0315\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0432\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0352\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0453\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0356\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0380\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0359\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0375\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0316\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0275\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0394\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0375\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0280\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0332\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0362\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0354\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0215\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0284\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0347\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0262\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0333\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0256\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0249\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0371\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0262\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0246\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0265\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0315\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0293\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0264\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0359\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0305\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0262\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0270\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0285\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0211\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0231\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0320\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0297\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0272\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0230\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0268\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0249\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0268\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0276\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0216\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0266\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0276\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0215\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0224\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0321\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0246\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020421D483A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.2730\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0698\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0591\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0627\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0696\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0698\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0595\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0519\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0651\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0447\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0473\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0453\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0483\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0479\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0517\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0452\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0598\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0439\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0366\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0396\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0535\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0344\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0281\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0467\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0297\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0402\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0499\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0347\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0348\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0264\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0336\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0296\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0326\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0356\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0356\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0357\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0260\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0274\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0341\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0252\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0311\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0291\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0296\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0258\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0279\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0322\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0275\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0216\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0321\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0253\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0238\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0224\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0291\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0285\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0232\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0300\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0207\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0235\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0289\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0296\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0255\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0239\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0235\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0245\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0277\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0207\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0233\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0216\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0300\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0214\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0228\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0211\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0235\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0185\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0225\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0200\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0218\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0202\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0256\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 0.0226\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020421901A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0825\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0372\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0279\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0243\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0306\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0205\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0249\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0308\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0268\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0189\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0216\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0292\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0205\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0215\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0219\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0137\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0155\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0264\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0189\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0249\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0180\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0141\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0161\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0149\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0139\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0152\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0169\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0171\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0197\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0153\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0188\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0137\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0154\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0144\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0171\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0122\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0146\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0130\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0149\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0160\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0146\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0156\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0118\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0110\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0106\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0157\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0122\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0158\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0114\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0099\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0138\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0114\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0105\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0138\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0089\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0101\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0159\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0103\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0112\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0105\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0124\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0111\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0142\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0125\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0101\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0117\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0108\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0122\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0124\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0081\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0123\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0115\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0139\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0100\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0106\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0089\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0106\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0085\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0097\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0094\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002042B34F5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.2433\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0479\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0470\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0480\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0477\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0512\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0460\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0322\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0511\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0427\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0377\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0529\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0278\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0495\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0358\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0294\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0312\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0395\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0264\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0307\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0424\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0210\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0309\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0259\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0346\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0225\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0396\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0267\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0333\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0247\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0295\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0229\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0197\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0281\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0292\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0258\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0211\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0250\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0318\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0216\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0223\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0292\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0250\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0259\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0244\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0281\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0192\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0212\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0226\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0258\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0203\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0209\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0224\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0222\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0199\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0171\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0291\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0200\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0173\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0178\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0222\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0202\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0187\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0233\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0186\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0143\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0183\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0237\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0202\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0168\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 0.0178\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0249\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0161\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0196\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0178\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0209\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0160\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0190\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0248\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.0202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204387B2828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.1548\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0491\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0515\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0458\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0383\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0358\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0400\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0421\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0495\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0357\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0338\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0302\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0317\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0319\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0288\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0337\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0427\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0320\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0355\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0288\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0286\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0384\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0258\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0231\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0265\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0354\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0287\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0266\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0341\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0233\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0263\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0233\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0221\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0226\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0299\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0223\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0309\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0260\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0261\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0244\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0189\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0254\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0215\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0279\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0193\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0270\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0186\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0258\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0176\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0228\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0206\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0240\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0211\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0205\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0218\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0206\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0171\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0234\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0156\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0196\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0203\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0197\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0185\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0213\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0159\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0195\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0205\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0175\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0187\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0189\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0148\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0173\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0189\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0257\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0183\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0144\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0176\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0161\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0174\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020395D36798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0949\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0505\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0377\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0452\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0337\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0424\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0364\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0264\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0309\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0283\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0282\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0307\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0360\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0289\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0236\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0188\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0200\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0205\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0292\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0126\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0161\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0212\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0167\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0187\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0184\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0183\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0172\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0207\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0162\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0147\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0153\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0140\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0193\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0132\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0135\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0163\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0141\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0134\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0132\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0141\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0164\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0159\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0205\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0153\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0128\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0158\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0130\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0118\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0110\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0131\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0155\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0116\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0148\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0133\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0150\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0105\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0099\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0134\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0121\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0110\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0138\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0143\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0131\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0117\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0097\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0107\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0122\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0098\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0148\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0152\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0095\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0138\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0119\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0102\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0114\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0124\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0125\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0107\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0096\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0106\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204307CD678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.1432\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0472\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0381\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0489\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0334\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0465\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0467\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0316\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0372\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0306\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0417\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0280\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0293\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0397\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0286\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0321\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0285\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0233\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0278\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0281\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0203\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0325\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0214\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0247\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0173\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0228\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0279\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0198\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0183\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0243\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0210\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0196\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0281\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0317\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0168\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0210\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0198\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0182\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0161\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0167\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0241\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0173\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0142\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0179\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0179\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0182\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0198\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0171\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0176\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0158\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0149\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0167\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0232\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0143\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0179\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0145\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0159\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0235\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0166\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0161\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0148\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0158\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0179\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0184\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0124\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0146\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0171\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0115\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0166\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0142\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0230\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0147\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0145\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0147\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0128\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0128\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0132\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0199\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0131\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203B7B46F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.1850\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0596\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0755\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0576\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0668\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0534\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0504\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0644\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0367\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0512\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0357\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0518\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0471\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0382\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0368\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0407\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0366\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0330\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0353\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0280\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0385\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0392\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0302\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0303\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0430\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0275\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0355\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0483\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0218\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0269\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0392\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0253\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0382\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0226\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0286\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0308\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0339\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0272\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0267\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0330\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0264\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0234\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0239\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0312\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0274\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0235\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0284\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0250\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0201\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0272\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0283\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0288\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0272\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0208\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0215\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0284\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0233\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0280\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0178\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0274\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0326\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0223\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0200\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0205\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0242\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0242\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0186\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0234\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0226\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0234\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0259\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0209\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0200\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0177\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0249\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0208\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0163\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0241\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0204\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020409FB6168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.2259\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0483\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0481\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0431\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0419\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0480\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0415\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0372\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0449\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0403\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0390\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0456\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0313\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0358\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0359\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0394\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0309\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0316\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0354\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0449\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0298\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0288\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0329\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0288\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0259\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0302\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0280\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0255\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0275\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0205\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0266\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0285\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0272\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0229\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0242\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0270\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0232\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0281\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0241\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0257\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0244\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0239\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0190\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0264\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0230\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0192\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0198\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0220\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0259\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0242\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0208\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0223\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0225\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0179\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0180\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0216\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0258\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0189\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0216\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0174\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0236\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0223\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0216\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0202\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0176\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0190\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0174\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0195\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0168\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0185\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0193\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0166\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0192\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0164\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0174\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0189\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0141\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0141\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0180\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204266E73A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0390\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0225\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0170\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0196\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0174\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0201\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0201\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0155\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0146\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0152\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0163\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0146\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0124\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0224\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0118\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0124\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0104\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0110\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0161\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0111\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0138\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0141\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0122\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0143\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0141\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0111\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0140\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0115\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0137\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0128\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0150\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0092\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0110\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0106\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0175\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0132\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0109\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0092\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0092\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0126\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0113\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0110\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0107\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0125\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0101\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0157\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.0108\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0102\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0090\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0087\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0107\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0112\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0125\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0098\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0092\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0091\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0082\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0110\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0095\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0108\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0106\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0125\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0127\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0089\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0098\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0100\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0098\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0115\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0112\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0086\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0111\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0093\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0135\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0094\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0094\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0116\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0103\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0075\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0092\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0096\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204205B6A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0497\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0212\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0201\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0192\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0159\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0191\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0143\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0156\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0122\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0168\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0142\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0154\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0135\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0140\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0167\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0172\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0118\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0147\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0123\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0132\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0158\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0111\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0106\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0118\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0182\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0136\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0109\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0110\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0120\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0111\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0141\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0112\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0137\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0101\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0107\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0108\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0146\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0123\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0112\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0128\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0091\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0106\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0105\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0083\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0169\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0105\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0102\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0112\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0110\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0111\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0103\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0109\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0100\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0087\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0087\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0105\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0081\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0098\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0100\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0119\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0090\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0072\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0092\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0096\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0086\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0104\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0084\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0109\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0094\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0094\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0130\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0097\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0084\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0074\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0094\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0091\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0073\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0106\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0077\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203FBCDB5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.1867\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0413\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0412\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0445\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0412\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0376\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0452\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0367\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0545\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0380\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0311\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0340\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0491\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0320\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0312\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0357\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0425\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0305\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0319\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0308\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0338\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0316\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0331\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0241\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0379\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0242\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0296\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0295\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0229\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0228\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0295\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0162\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0276\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0262\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0175\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0226\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0281\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0248\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0214\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0280\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0202\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0230\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0228\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0235\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0233\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0188\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0221\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0183\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0185\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0213\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0182\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0234\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0213\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0243\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0218\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0166\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0192\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0206\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0167\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0199\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0168\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0173\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0183\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0150\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0153\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0196\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0215\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0192\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0147\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0162\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0159\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0212\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0133\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0158\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0157\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0129\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0144\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0152\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0163\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0176\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002043D257828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.1319\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0671\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0614\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0514\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0517\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0482\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0532\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0444\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0379\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0547\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0401\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0361\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0466\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0390\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0365\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0414\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0393\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0405\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0371\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0334\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0291\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0426\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0361\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0250\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0363\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0270\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0506\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0239\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0321\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0264\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0227\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0267\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0254\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0296\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0300\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0282\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0258\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0260\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0271\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0209\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0257\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0221\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0238\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0266\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0266\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0209\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0196\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0251\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0206\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0221\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0265\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0287\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0250\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0202\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0222\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0291\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0183\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0233\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0178\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0248\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0199\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0221\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0271\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0171\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0226\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0237\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0175\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0224\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0231\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0207\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0222\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0165\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0233\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0179\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0203\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0222\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0178\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0200\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0171\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0195\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204462C4E58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0770\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0492\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0233\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0255\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0254\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0289\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0217\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0217\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0213\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0202\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0291\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0274\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0226\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0191\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0180\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0240\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0212\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0204\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0208\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0192\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0221\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0180\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0228\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0180\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0242\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0177\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0146\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0130\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0181\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0173\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0196\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0158\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0164\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0195\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0164\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0143\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0160\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0154\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0205\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0172\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0161\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0153\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0137\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0126\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0131\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0154\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0131\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0161\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0129\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0131\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0161\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0112\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0127\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0139\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0136\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0151\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0191\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0123\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0118\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0130\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0125\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0172\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0113\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0148\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0131\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0120\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0114\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0132\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0131\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0139\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0112\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0112\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0152\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0127\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0118\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0146\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0105\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0121\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0101\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0125\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203D1303798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0855\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0409\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0303\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0289\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0247\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0225\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0341\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0234\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0230\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0205\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0203\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0154\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0240\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0233\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0143\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0163\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0154\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0265\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0128\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0191\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0131\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0205\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0158\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0145\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0156\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0139\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0134\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0184\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0148\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0136\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0134\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0105\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0130\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0165\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0131\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0125\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0131\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0155\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0123\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0127\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0136\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0127\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0097\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0126\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0160\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0098\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0116\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0114\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0132\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0107\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0120\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0096\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0118\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0098\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0131\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0135\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0122\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0123\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0108\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0097\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0106\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0111\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0095\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0106\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0093\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0106\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0107\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0112\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0124\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0099\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0118\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0121\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0115\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0089\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0104\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0104\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0095\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0121\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0083\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0109\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002043CF96E58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.2317\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0621\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0571\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0597\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0530\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0483\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0640\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0423\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0525\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0357\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0446\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0520\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0382\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0456\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0439\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0388\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0440\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0458\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0347\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0387\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0320\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0410\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0343\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0293\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0462\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0310\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0312\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0350\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0307\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0283\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0345\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0433\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0327\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0270\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0287\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0286\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0346\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0273\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0349\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0282\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0303\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0252\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0289\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0293\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0261\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0250\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0222\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0189\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0346\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0232\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0221\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0216\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0183\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0331\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0269\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0268\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0253\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0220\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0199\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0263\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0263\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0220\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0167\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0256\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0208\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0203\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0220\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0188\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0254\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0240\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0204\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0164\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0207\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0219\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0176\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0280\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0168\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0158\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0178\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204155F1DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.1442\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0606\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0551\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0326\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0436\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0476\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0548\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0340\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0263\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0453\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0264\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0276\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0435\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0303\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0275\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0224\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0384\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0208\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0210\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0364\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0196\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0213\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0347\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0189\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0222\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0287\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0203\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0214\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0226\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0179\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0228\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0298\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0141\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0244\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0209\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0180\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0203\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0277\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0230\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0206\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0209\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0227\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0176\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0172\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0196\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0199\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0232\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0165\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0169\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0155\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0245\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0145\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0201\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0220\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0190\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0212\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0149\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0154\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0182\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0165\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0144\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0174\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0147\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0209\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0164\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0133\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0182\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0149\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0109\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0148\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0160\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0147\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0148\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0222\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0130\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0116\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0142\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0157\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0194\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0131\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020421D483A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.2685\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0785\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0599\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0518\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0713\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0660\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0515\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0888\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0672\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0563\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0524\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0473\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0581\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0549\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0473\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0498\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0407\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0631\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0476\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0494\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0478\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0466\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0526\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0478\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0452\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0423\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0568\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0450\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0433\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0415\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0424\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0425\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0368\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0421\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0462\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0417\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0405\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0417\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0439\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0380\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0433\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0353\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0348\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0361\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0319\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0401\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0428\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0384\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0414\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0317\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0383\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0344\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0321\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0434\n",
      "Epoch 55/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0344\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0347\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0346\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0326\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0402\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0370\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0394\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0303\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0349\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0401\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0319\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0267\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0373\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0248\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0347\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0361\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0343\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0279\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0333\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0301\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0282\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0443\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0335\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0298\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0359\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0276\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203E388BE58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.1595\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0472\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0561\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0680\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0487\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0378\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0522\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0535\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0475\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0288\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0536\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0371\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0349\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0256\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0502\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0307\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0428\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0348\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0250\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0460\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0287\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0353\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0292\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0245\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0354\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0366\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0309\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0253\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0240\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0230\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0279\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0275\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0268\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0284\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0244\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0268\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0275\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0293\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0208\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0210\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0260\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0263\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0225\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0215\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0247\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0195\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0165\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0262\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0262\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0257\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0207\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0165\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0228\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0206\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0191\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0245\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0176\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0228\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0173\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0220\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0226\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0199\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0160\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0238\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0231\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0180\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0144\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0225\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0158\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0167\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0149\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0149\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0144\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0209\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0151\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0213\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0176\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0170\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0178\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020404AA8948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.2125\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0655\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0457\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0721\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0535\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0531\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0519\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0508\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0640\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0505\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0403\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0551\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0446\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0422\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0449\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0357\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0470\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0485\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0373\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0307\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0347\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0370\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0367\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0479\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0404\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0431\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0270\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0324\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0277\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0429\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0273\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0265\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0275\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0270\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0321\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0323\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0211\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0286\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0227\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0246\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0377\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0270\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0211\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0293\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0291\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0283\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0229\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0303\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0244\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0256\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0365\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0226\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0234\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0223\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0218\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0245\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0249\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0246\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0290\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0240\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0214\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0184\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0216\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0186\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0254\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0244\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0260\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0206\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0239\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0182\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0174\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0194\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0194\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0193\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0182\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0164\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0192\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0253\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0160\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0181\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020449A2EEE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.2226\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0457\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0394\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0407\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0491\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0454\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0680\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0415\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0404\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0515\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0365\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0407\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0495\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0478\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0351\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0336\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0404\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0372\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0391\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0304\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0421\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0451\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0369\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0338\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0356\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0323\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0349\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0400\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0430\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0284\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0436\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0361\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0281\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0232\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0471\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0292\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0297\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0308\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0316\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0281\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0336\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0410\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0274\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0282\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0354\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0348\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0287\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0275\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0263\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0289\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0303\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0201\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0342\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0277\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0286\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0357\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0303\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0292\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0263\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0323\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0240\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0296\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0272\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0288\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0284\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0266\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0257\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0290\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0291\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0219\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0311\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0233\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0211\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0269\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0209\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0216\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0220\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0269\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0212\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0193\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020453AC0708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.2272\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0822\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0768\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0706\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0756\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0649\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0726\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0654\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0672\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0598\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0665\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0512\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0685\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0566\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0497\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0538\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0477\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0374\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0542\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0346\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0414\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0420\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0549\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0332\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0398\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0376\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0414\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0364\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0511\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0326\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0327\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0554\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0397\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0290\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0365\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0360\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0288\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0327\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0334\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0297\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0294\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0273\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0212\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0263\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0343\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0251\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0376\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0199\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0227\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0303\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0204\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0343\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0259\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0230\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0330\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0282\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0212\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0208\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0231\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0325\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0227\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0242\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0248\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0219\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0251\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0257\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0198\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0199\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0197\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0195\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0220\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0170\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0264\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0165\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0232\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0212\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0210\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0224\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0233\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0208\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002045DB0FDC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.1720\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0600\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0709\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0452\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0545\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0625\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0487\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0417\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0436\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0482\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0462\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0430\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0465\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0471\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0419\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0377\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0422\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0468\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0415\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0403\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0330\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0335\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0330\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0384\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0308\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0390\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0357\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0299\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0354\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0271\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0307\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0317\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0283\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0364\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0333\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0285\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0329\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0252\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0268\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0354\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0252\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0295\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0324\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0275\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0234\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0280\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0255\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0223\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0261\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0266\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0254\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0243\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0257\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0211\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0301\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0229\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0313\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0265\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0226\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0230\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0206\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0231\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0248\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0233\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0305\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0239\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0260\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0250\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0242\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0229\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0207\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0228\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0253\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0245\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0223\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0208\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0266\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0228\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0242\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020395DFDEE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.2687\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0792\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0759\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0627\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0670\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0531\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0753\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0610\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0662\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0549\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0531\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0598\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0478\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0478\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0658\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0484\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.0615\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0503\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0482\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0474\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0533\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0496\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0603\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0525\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0403\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0352\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0500\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0430\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0512\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0368\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0350\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0468\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0470\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0387\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0483\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0445\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0383\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0431\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0389\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0413\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0416\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0436\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0376\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0342\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0412\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0398\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0417\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0382\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0413\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0370\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0467\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0311\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.0359\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0409\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0317\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0385\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0284\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0355\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0284\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0368\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0366\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0314\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0328\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0342\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0316\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0323\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0324\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0307\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0350\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0328\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0326\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0290\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0279\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0364\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0322\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0397\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.0337\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0362\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0280\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0246\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203F726E438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.1279\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0376\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0332\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0355\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0395\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0452\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0346\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0334\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0365\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0270\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0320\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0381\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0364\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0356\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0246\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0207\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0272\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0255\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0397\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0223\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0301\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0269\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0226\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0306\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0237\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0383\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0270\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0250\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0289\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0229\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0254\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0253\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0255\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0231\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0270\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0200\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0266\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0267\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0290\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0215\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0284\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0239\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0179\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0194\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0272\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0168\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0191\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0190\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0171\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0249\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0212\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0290\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0188\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0176\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0201\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0214\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0260\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0187\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0160\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0205\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0202\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0189\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0216\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0205\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0201\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0150\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0231\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0187\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0182\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0160\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0169\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0158\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0169\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0140\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0161\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0194\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0161\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0155\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0146\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020449651F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.1519\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0715\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0903\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0545\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0542\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0668\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0528\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0552\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0479\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0478\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0545\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0398\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0497\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0507\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0403\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0583\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0355\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0534\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0399\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0476\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0463\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0398\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0454\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0380\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0346\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0372\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0480\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0367\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0361\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0419\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0271\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0369\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0309\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0356\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0461\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0299\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0331\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0287\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0374\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0370\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0298\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0323\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0326\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0333\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0276\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0349\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0307\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0297\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0250\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0291\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0425\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0305\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0278\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0309\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0267\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0238\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0255\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0311\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0309\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0279\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0360\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0284\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0241\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0311\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0357\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 220ms/step - loss: 0.0210\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0258\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0280\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0250\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0254\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0238\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0249\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0231\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0218\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0197\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0264\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0199\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0197\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0229\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0261\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020406E95948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.1300\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0368\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0312\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0288\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0251\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0242\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0224\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0232\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0378\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0243\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0322\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0247\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0210\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0235\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0225\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0202\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0236\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0237\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0292\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0181\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0182\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0191\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0244\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0233\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0205\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0213\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0190\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0161\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0195\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0214\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0143\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0186\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0190\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0126\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0158\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0172\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0184\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0152\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0141\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0224\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0148\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0175\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0181\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0128\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0144\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0140\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0143\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0117\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0100\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0109\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0140\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0165\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0108\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0094\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0098\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0141\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0109\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0122\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0075\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0095\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0101\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0133\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0100\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0096\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0121\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0097\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0106\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0094\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.0082\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0092\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0071\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0105\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0090\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0090\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0088\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0063\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0084\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0068\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0086\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0102\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002038B97A3A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0642\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0260\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0228\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0224\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0213\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0222\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0216\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0203\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0221\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0194\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0229\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0142\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0185\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0144\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0168\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0129\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0161\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0141\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0189\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0155\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0124\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0196\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0104\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0115\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0154\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0104\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0132\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0126\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0126\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0107\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0109\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0195\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0112\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0090\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0102\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0078\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0100\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0106\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0094\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0160\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0091\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0097\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0104\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0094\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0090\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0075\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0110\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0112\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0074\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0105\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0085\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0107\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0081\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0068\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0099\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0089\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0077\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0073\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0096\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0097\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0076\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0095\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0107\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0075\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0081\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0101\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0069\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0087\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0081\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0068\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0071\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0069\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0064\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0079\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0066\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0074\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0084\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0059\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0102\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0061\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204409EEAF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.1785\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0539\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0547\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0428\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0447\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0366\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0547\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0388\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0464\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0414\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0390\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0459\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0386\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0366\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0283\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0334\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0344\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0359\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0352\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0396\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0380\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0277\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0268\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0360\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0261\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0282\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0305\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0317\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0274\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0268\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0268\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0269\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0238\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0386\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0206\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0203\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0231\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0264\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0246\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0312\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0242\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0246\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0269\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0257\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0251\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0207\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0219\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0260\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0253\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0223\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0269\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0278\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0218\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0258\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0200\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0203\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0212\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0235\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0255\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0208\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0230\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0256\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0226\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0217\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0217\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0199\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0302\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0232\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0245\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0238\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0198\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0230\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0191\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0203\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0227\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0196\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0232\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0225\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0180\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002043745A5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.1654\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0678\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0649\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0494\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0524\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0503\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0495\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0481\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0394\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0531\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0375\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0428\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0336\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0448\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0410\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0431\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0379\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0339\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0343\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0450\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0326\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0359\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0335\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0316\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0340\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0337\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0347\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0382\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0274\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0303\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0312\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0256\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0248\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0315\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0261\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0296\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0201\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0254\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0246\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0255\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0224\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0308\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0254\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0180\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0184\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0220\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0207\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0216\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0178\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0230\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0231\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0157\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0247\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0172\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0155\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0241\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0205\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0193\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0188\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0199\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0171\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0190\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0157\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0176\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0157\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0148\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0144\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0161\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0171\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0156\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0127\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0159\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0180\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0155\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0158\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0141\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0131\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0122\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0119\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204529BA828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.1314\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0404\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0416\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0423\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0400\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0480\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0399\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0428\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0349\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0440\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0365\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0333\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0442\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0407\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0375\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0288\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0400\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0340\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0272\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0388\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0247\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0300\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0334\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0358\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0304\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0242\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0270\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0301\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0214\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0263\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0293\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0280\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0251\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0250\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0202\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0317\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0241\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0244\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0197\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0280\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0209\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0242\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0200\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0184\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0178\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0185\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0261\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0225\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0253\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0242\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0224\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0211\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0184\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0228\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0175\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0192\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0209\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0180\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0191\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0198\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0225\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0207\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0202\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0221\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0216\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0177\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0190\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0178\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0190\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0149\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0189\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0170\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0201\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0150\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0205\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0197\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0187\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0172\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0224\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0169\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020467820D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.1138\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0413\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0528\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0580\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0480\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0327\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0311\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0486\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0339\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0455\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0332\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0462\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0279\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0365\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0309\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0308\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0418\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0334\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0264\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0219\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0311\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0275\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0281\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0289\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0307\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0241\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0241\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0274\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0389\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0270\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0214\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0251\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0265\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0217\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0231\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0245\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0262\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0198\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0335\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0233\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0197\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0212\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0219\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0277\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0227\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0235\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0241\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0173\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0164\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0188\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0211\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0235\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0232\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0222\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0254\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0189\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0205\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0237\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0298\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0219\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0182\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0203\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0186\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0165\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0233\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0157\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0231\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0201\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0154\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0155\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0250\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0185\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0156\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0140\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0222\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0155\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0197\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0197\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0163\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0243\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002046D96F5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0916\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0374\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0331\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0329\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0304\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0278\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0260\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0348\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0281\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0276\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0190\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0238\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0200\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0201\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0246\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0177\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0199\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0156\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0169\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0168\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0211\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0162\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0126\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0183\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0207\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0203\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0181\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0229\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0149\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0160\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0171\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0111\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0158\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0180\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0149\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0190\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0120\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0222\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0140\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0161\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0138\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0147\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0139\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0106\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0133\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0131\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0174\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0113\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0191\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0175\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0126\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0112\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0158\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0159\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0140\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0107\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0190\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0150\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0125\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0101\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0116\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0139\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0148\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0121\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0124\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0166\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0135\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0123\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0139\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0133\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0136\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0124\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0148\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0132\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0119\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0130\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0118\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0104\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0120\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0166\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020443F6E288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.2118\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0563\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0650\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0531\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0595\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0462\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0560\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0475\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0720\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0455\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0408\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0528\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0389\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0530\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0386\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0347\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0534\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0479\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0354\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0368\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0464\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0394\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0528\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0382\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0411\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0426\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0328\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0356\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0336\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0402\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0337\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0378\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0259\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0443\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0343\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0409\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0284\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0270\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0361\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0278\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0378\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0370\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0336\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0265\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0361\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0303\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0322\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0292\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0284\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0322\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0235\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0257\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0320\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0317\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0261\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0300\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0246\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0297\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0348\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 2s 304ms/step - loss: 0.0230\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 277ms/step - loss: 0.0240\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0246\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0228\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0274\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0265\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0264\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0229\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0266\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0229\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0249\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0218\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0297\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0272\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0279\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0254\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0190\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0257\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0219\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0195\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.0205\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020456D484C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.2047\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0564\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0671\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0532\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0529\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0518\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0550\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0496\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0377\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0414\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0708\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0297\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0381\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0403\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0405\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0260\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0314\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0265\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0448\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0304\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0354\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0361\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0259\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0287\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0284\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0317\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0338\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0291\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0385\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0292\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0234\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0261\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0263\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0218\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0240\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0377\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0200\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0304\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0280\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0288\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0346\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0196\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0230\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0249\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0268\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0204\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0263\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0209\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0220\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0297\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0231\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0250\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0199\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0231\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0242\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0269\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0207\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0194\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0166\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0250\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0212\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0265\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0170\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0178\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0177\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0270\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0162\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0167\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0206\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0204\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0188\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0207\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0189\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0200\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0165\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0272\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0193\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0166\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0164\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0184\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002042A15D4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.1648\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0811\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0586\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0530\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0599\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0390\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0467\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0608\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0443\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0650\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0503\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0456\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0380\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0336\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0346\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0389\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0358\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0465\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0394\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0314\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0372\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0293\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0306\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0291\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0303\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0233\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0241\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0324\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0228\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0344\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0250\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0269\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0238\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0245\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0311\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0193\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0260\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0260\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0237\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0213\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0212\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0273\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0241\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0181\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0202\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0238\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0200\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0211\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0206\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0206\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0191\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0264\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0209\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0257\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0170\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0174\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0190\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0222\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0216\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0206\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0233\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0172\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0202\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0173\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0183\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0211\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0207\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0151\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0177\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0199\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0198\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0154\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0163\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0225\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0187\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0159\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0153\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0193\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.0188\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0176\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203F9848948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.1505\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0860\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0460\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.0502\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0429\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0341\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0375\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0346\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0545\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0315\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0362\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0292\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0276\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0465\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0375\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0328\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0276\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0337\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0404\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0293\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0411\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0266\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0368\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0354\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.0366\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0241\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0315\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0345\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0358\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0237\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0286\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0365\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0304\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0269\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0236\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0288\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0285\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0301\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0232\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0235\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0284\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0214\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0256\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0240\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0277\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0236\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0295\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0254\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0235\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0187\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0267\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0247\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0353\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0257\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0220\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0231\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0306\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0188\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0282\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0238\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0251\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0207\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0247\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0187\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0256\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0244\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.0210\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0209\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0216\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0207\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0266\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0186\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0299\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0265\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0219\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0280\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0245\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0228\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0201\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0193\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002043CC2CE58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.1458\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0584\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0479\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0458\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0465\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0442\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0335\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0360\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0402\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0404\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0333\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0337\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0283\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0317\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0367\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0248\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0304\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0325\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0379\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0248\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0288\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0237\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0213\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0270\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0249\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0272\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0275\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0273\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0284\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0163\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0244\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0203\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0256\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0173\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0217\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0214\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0193\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0234\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0231\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0178\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0224\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0206\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0154\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0248\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0164\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0197\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0206\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0140\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0246\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0178\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0199\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0150\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0211\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0189\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0157\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0204\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0106\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0214\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0157\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0149\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0162\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0203\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0133\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0163\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0139\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0186\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0133\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0127\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0112\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0190\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0115\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0171\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0133\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0171\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0135\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0095\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0135\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0182\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0095\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020343490AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2005\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0746\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0522\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0642\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0536\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0485\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0521\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0430\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0436\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0734\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0375\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0392\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0378\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0327\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0379\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0574\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0402\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0344\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0348\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0341\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0372\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0448\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0418\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0357\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0352\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0394\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0288\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0348\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0322\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0266\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0422\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0268\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0376\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0293\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0252\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0305\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0262\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0254\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0323\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0207\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0347\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0268\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0338\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0289\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0263\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0281\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0356\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0235\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0246\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0271\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0224\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0257\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0283\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0242\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0271\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0237\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0222\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0251\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0216\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0258\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0191\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0196\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0232\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0260\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0236\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0227\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0204\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0203\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0234\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0251\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0223\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0243\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0221\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0235\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0154\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0206\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0178\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0240\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0171\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0220\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002042C3FACA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.1215\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0592\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0555\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0470\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0438\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0479\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0381\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0510\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0370\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0545\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0464\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0426\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0360\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0296\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0294\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0341\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0387\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0332\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0268\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0396\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0371\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0290\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0239\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0308\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0269\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0302\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0243\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0285\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0270\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0258\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0201\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0209\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0306\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0235\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0202\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0288\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0247\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0297\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0205\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0230\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0229\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0331\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0263\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0190\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0210\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0207\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0253\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0301\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0190\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0176\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0156\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0194\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0220\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0150\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0165\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0227\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0211\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0199\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0202\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0160\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0173\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0173\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0273\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0157\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0172\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0209\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0157\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0157\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0172\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0213\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0247\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0146\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0189\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0132\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0136\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0215\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0146\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0160\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0183\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0157\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002046545F3A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.1554\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0653\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0461\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0472\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0375\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0413\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0422\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0409\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0387\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0427\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0346\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0286\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0423\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0305\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0255\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0229\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0302\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0239\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0316\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0379\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0258\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0290\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0295\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0245\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0241\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0362\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0203\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0203\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0311\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0222\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0316\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0206\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0183\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0252\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0238\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0198\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0227\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0195\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.0277\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0183\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0180\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0195\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0290\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0163\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0191\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0221\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0301\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0180\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0189\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0191\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0160\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0190\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0183\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0206\n",
      "Epoch 55/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0192\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0166\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0189\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0170\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0188\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0211\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0170\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0156\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0145\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0204\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0187\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0152\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0160\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0212\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0189\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0179\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0154\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0197\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.0191\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0164\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0136\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0202\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0144\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0146\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0154\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0141\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020475817A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#Running the LSTM model on a random sample of stocks\n",
    "random_samples = random.choices(test_ind3.index.get_level_values(0).unique(), k=100)\n",
    "features = ['close', 'move_avg_7', 'intra_pct']\n",
    "lstm_test = {}\n",
    "ltsm_pred = {}\n",
    "for x in random_samples:\n",
    "    try:\n",
    "        test_ind3_sub = test_ind3.loc[x][features]\n",
    "        test_ind3_sub['move_avg_7'].replace(to_replace=0, method='bfill', inplace=True)\n",
    "        training_set = test_ind3_sub[:date_list[220]].iloc[:,0:1].values\n",
    "        test_set = test_ind3_sub[date_list[220]:].iloc[:,0:1].values\n",
    "        sc = MinMaxScaler(feature_range=(0,1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for i in range(60,220):\n",
    "            X_train.append(training_set_scaled[i-60:i,0])\n",
    "            y_train.append(training_set_scaled[i,0])\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
    "        # The LSTM architecture\n",
    "        regressor = Sequential()\n",
    "        # First LSTM layer with Dropout regularisation\n",
    "        regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "        regressor.add(Dropout(0.5))\n",
    "        # Second LSTM layer\n",
    "        regressor.add(LSTM(units=50, return_sequences=True))\n",
    "        regressor.add(Dropout(0.5))\n",
    "        # Third LSTM layer\n",
    "        regressor.add(LSTM(units=50, return_sequences=True))\n",
    "        regressor.add(Dropout(0.5))\n",
    "        # Fourth LSTM layer\n",
    "        regressor.add(LSTM(units=50))\n",
    "        regressor.add(Dropout(0.5))\n",
    "        # The output layer\n",
    "        regressor.add(Dense(units=1))\n",
    "        # Compiling the RNN\n",
    "        regressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n",
    "        # Fitting to the training set\n",
    "        regressor.fit(X_train,y_train,epochs=80,batch_size=32)\n",
    "        dataset_total = pd.concat((test_ind3_sub['close'][:date_list[220]], \\\n",
    "                                   test_ind3_sub['close'][date_list[220]:]),axis=0)\n",
    "        inputs = dataset_total[len(dataset_total)-len(test_set) - 60:].values\n",
    "        inputs = inputs.reshape(-1,1)\n",
    "        inputs  = sc.transform(inputs)\n",
    "        X_test = []\n",
    "        for i in range(60,92):\n",
    "            X_test.append(inputs[i-60:i,0])\n",
    "        X_test = np.array(X_test)\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "        predicted_stock_price = regressor.predict(X_test)\n",
    "        predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "        lstm_test[x] = test_set\n",
    "        ltsm_pred[x] = predicted_stock_price\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing for Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating all of the drop down lists I will use for the graph tool\n",
    "#Also creating a list of 'None' values that will be used in graphing\n",
    "none_list = []\n",
    "for x in range(len(date_list)):\n",
    "    none_list.append(None)\n",
    "    \n",
    "sector_name = widgets.Dropdown(options=sector_list, description='Sector')\n",
    "sector_stocks = widgets.Dropdown(options=list(sym_delta.index), description='Stock Symbol')\n",
    "\n",
    "def update_sector(*args):\n",
    "    sector_stocks.options = list(sym_delta[sym_delta['sector'] == sector_name.value].index)\n",
    "sector_name.observe(update_sector, 'value')\n",
    "stock_symbol = widgets.Dropdown(options=list(sym_delta.index), \\\n",
    "                               description='Stock Symbol')\n",
    "yield_curve = widgets.Dropdown(options=[('30yr vs 5yr Yield Difference','30yr5yr'),\\\n",
    "                                        ('10yr vs 2yr Yield Difference','10yr2yr')], \\\n",
    "                               description='Yield Curve')\n",
    "random_stocks = widgets.Dropdown(options=list(ltsm_pred.keys()), \\\n",
    "                               description='Stock Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph comparing sectors\n",
    "def sector_compare():    \n",
    "    fig = px.line(sectval_df, x='date', y=sectval_df.columns,\n",
    "                  title='Sector Indices')\n",
    "    fig.update_traces(mode='lines', hovertemplate=None)\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_layout(hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphing an lstm forecast\n",
    "def lstm_forecast(random_stocks):\n",
    "    test_set_list = []\n",
    "    predicted_stock_list = []\n",
    "    for x in lstm_test[random_stocks]:\n",
    "        test_set_list.append(x[0])\n",
    "    for x in ltsm_pred[random_stocks]:\n",
    "        predicted_stock_list.append(x[0])\n",
    "    fig = go.Figure()\n",
    "    return_rmse(lstm_test[random_stocks],ltsm_pred[random_stocks])\n",
    "    fig.add_trace(go.Scatter(x=date_list[220:], y=test_set_list,\n",
    "                        mode='lines',\n",
    "                        name=random_stocks+' Value'))\n",
    "    fig.add_trace(go.Scatter(x=date_list[220:], y=predicted_stock_list,\n",
    "                        mode='lines',\n",
    "                        name='Prediction'))\n",
    "    fig.update_traces(mode='lines', hovertemplate=None)\n",
    "    fig.update_layout(title='Testing Predictions Using LSTM',\n",
    "                       xaxis_title='Date',\n",
    "                       yaxis_title='Price')\n",
    "    fig.update_layout(hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphing a step ahead forecast\n",
    "def step_ahead_forecast(stock_symbol):\n",
    "    fig = go.Figure()\n",
    "    conf_list = stock_pred_df.loc[stock_symbol, 'pred_conf']\n",
    "    pred_list = stock_pred_df.loc[stock_symbol, 'pred_vals']\n",
    "    lower_conf = []\n",
    "    upper_conf = []\n",
    "    for x in range(len(conf_list)):\n",
    "        lower_conf.append(conf_list[x,0])\n",
    "        upper_conf.append(conf_list[x,1])\n",
    "\n",
    "    x_values = list(stockval_df['date'])\n",
    "    x_rev = x_values[::-1]\n",
    "\n",
    "    y1 = none_list[:180]\n",
    "    y1.extend(pred_list)\n",
    "    y1_upper = none_list[:180]\n",
    "    y1_upper.extend(upper_conf)\n",
    "    y1_lower = none_list[:180]\n",
    "    y1_lower.extend(lower_conf)\n",
    "    y1_lower = y1_lower[::-1]\n",
    "\n",
    "    y2 = list(stockval_df[stock_symbol])\n",
    "    return_rmse(y2[180:],pred_list)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values+x_rev,\n",
    "        y=y1_upper+y1_lower,\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(0,100,80,0.2)',\n",
    "        line_color='rgba(255,255,255,0)',\n",
    "        showlegend=False))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values, y=y1,\n",
    "        line_color='rgb(0,100,80)',\n",
    "        name='predictions'))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values, y=y2,\n",
    "        line_color='rgb(0,176,246)',\n",
    "        name='Stock: '+stock_symbol))\n",
    "    fig.update_traces(mode='lines', hovertemplate=None)\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_layout(\n",
    "        title='One Step Ahead Forecast',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Index Value',\n",
    "        hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a graph to plot yield against stock price\n",
    "def yield_stock(stock_symbol, yield_curve):\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    x_values = list(stockval_df['date'])\n",
    "    y1 = list(yield_comb[yield_curve])\n",
    "    y2 = list(stockval_df[stock_symbol])\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values, y=y1,\n",
    "        line_color='rgb(0,100,80)',\n",
    "        name='Yield Diff'), secondary_y=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values, y=y2,\n",
    "        line_color='rgb(0,176,246)',\n",
    "        name='Stock: '+stock_symbol),\n",
    "        secondary_y=False)\n",
    "    fig.update_traces(mode='lines', hovertemplate=None)\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_yaxes(title_text=\"Stock Value\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Yield Differential\", secondary_y=True)\n",
    "    fig.update_layout(\n",
    "        title='Yield Curve vs. Stock Value',\n",
    "        xaxis_title='Date', hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a graph to plot yield against sector index\n",
    "def yield_sect(sector_name, yield_curve):\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    x_values = list(sectval_df['date'])\n",
    "    y1 = list(yield_comb[yield_curve])\n",
    "    y2 = list(sectval_df[sector_name])\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values, y=y1,\n",
    "        line_color='rgb(0,100,80)',\n",
    "        name='Yield Diff'), secondary_y=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values, y=y2,\n",
    "        line_color='rgb(0,176,246)',\n",
    "        name='Sector: '+sector_name),\n",
    "        secondary_y=False)\n",
    "    fig.update_traces(mode='lines', hovertemplate=None)\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_yaxes(title_text=\"Sector Index\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Yield Differential\", secondary_y=True)\n",
    "    fig.update_layout(\n",
    "        title='Yield Curve vs. Sector Index',\n",
    "        xaxis_title='Date', hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to graph a stock vs its sector\n",
    "#Also graphs the predicted values\n",
    "def stock_vs_sector(sector_name, sector_stocks):\n",
    "    fig = go.Figure()\n",
    "    scalar = stockval_df.loc[0, sector_stocks] / sectval_df.loc[0, sector_name] * sectval_df.loc[0, sector_name] / 100\n",
    "    for y in [sector_name, sector_stocks]:\n",
    "        forecast_dates = pd.date_range(start=dt_index[-1], periods=6, freq=bday_us)\n",
    "        forecast_dates = list(forecast_dates[1:])\n",
    "        if y == sector_name:\n",
    "            conf_list = pred_df.loc[sector_name, 'forecast_conf']\n",
    "            pred_list = pred_df.loc[sector_name, 'forecast_vals']\n",
    "            lower_conf = []\n",
    "            upper_conf = []\n",
    "            for x in range(len(conf_list)):\n",
    "                lower_conf.append(conf_list[x,0])\n",
    "                upper_conf.append(conf_list[x,1])\n",
    "            y2 = list(np.array(sectval_df[sector_name])*scalar)\n",
    "            x_values = list(sectval_df['date'])\n",
    "            x_values.extend(forecast_dates)\n",
    "            x_rev = x_values[::-1]\n",
    "            y1 = none_list[:-1]\n",
    "            y1.append(y2[-1])\n",
    "            y1.extend(np.array(pred_list)*scalar)\n",
    "            y1_upper = none_list[:-1]\n",
    "            y1_upper.append(y2[-1])\n",
    "            y1_upper.extend(np.array(upper_conf)*scalar)\n",
    "            y1_lower = none_list[:-1]\n",
    "            y1_lower.append(y2[-1])\n",
    "            y1_lower.extend(np.array(lower_conf)*scalar)\n",
    "            y1_lower = y1_lower[::-1]\n",
    "            y2.extend(none_list[:5])\n",
    "        elif y == sector_stocks:\n",
    "            conf_list = stock_pred_df.loc[sector_stocks, 'forecast_conf']\n",
    "            pred_list = stock_pred_df.loc[sector_stocks, 'forecast_vals']\n",
    "            lower_conf = []\n",
    "            upper_conf = []\n",
    "            for x in range(len(conf_list)):\n",
    "                lower_conf.append(conf_list[x,0])\n",
    "                upper_conf.append(conf_list[x,1])\n",
    "            y2 = list(stockval_df[sector_stocks])\n",
    "            x_values = list(sectval_df['date'])\n",
    "            x_values.extend(forecast_dates)\n",
    "            x_rev = x_values[::-1]\n",
    "            y1 = none_list[:-1]\n",
    "            y1.append(y2[-1])\n",
    "            y1.extend(pred_list)\n",
    "            y1_upper = none_list[:-1]\n",
    "            y1_upper.append(y2[-1])\n",
    "            y1_upper.extend(upper_conf)\n",
    "            y1_lower = none_list[:-1]\n",
    "            y1_lower.append(y2[-1])\n",
    "            y1_lower.extend(lower_conf)\n",
    "            y1_lower = y1_lower[::-1]\n",
    "            y2.extend(none_list[:5])\n",
    "        \n",
    "        if y == sector_name:\n",
    "            fig.add_trace(go.Scatter(x=x_values+x_rev,\n",
    "                y=y1_upper+y1_lower, fill='toself',\n",
    "                fillcolor='rgba(0,100,80,0.2)',\n",
    "                line_color='rgba(255,255,255,0)',showlegend=False))\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y1,\n",
    "                line_color='rgb(0,100,80)', name='Sector forecast'))\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y2,\n",
    "                line_color='rgb(0,176,246)', name=sector_name))\n",
    "        elif y == sector_stocks:\n",
    "            fig.add_trace(go.Scatter(x=x_values+x_rev,\n",
    "                y=y1_upper+y1_lower, fill='toself',\n",
    "                fillcolor='rgba(0,100,80,0.2)',\n",
    "                line_color='rgba(255,255,255,0)',showlegend=False))\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y1,\n",
    "                line_color='rgb(0,100,80)', name='Stock forecast'))\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y2,\n",
    "                line_color='rgb(50,20,80)', name='Stock: '+sector_stocks))\n",
    "   \n",
    "    fig.update_traces(mode='lines', hovertemplate=None)\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_layout(\n",
    "        title='Five Day Forecast - Stock vs. Sector', xaxis_title='Date',\n",
    "        yaxis_title='Stock Value', hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to graph a stock vs its sector \n",
    "#Also graphs the predicted values\n",
    "#Similar to previous graph but returns a table as well\n",
    "def stock_vs_sector_table(sector_name, sector_stocks):\n",
    "    fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.03,\n",
    "    specs=[[{\"type\": \"table\"}],\n",
    "           [{\"type\": \"scatter\"}]])\n",
    "    scalar = stockval_df.loc[0, sector_stocks] / sectval_df.loc[0, sector_name] * sectval_df.loc[0, sector_name] / 100\n",
    "    stock_last = round(list(stockval_df[sector_stocks])[-1], 2)\n",
    "    sect_last = round(list(sectval_df[sector_name])[-1]*scalar, 2)\n",
    "    for y in [sector_name, sector_stocks]:\n",
    "        forecast_dates = pd.date_range(start=dt_index[-1], periods=6, freq=bday_us)\n",
    "        forecast_dates = list(forecast_dates[1:])\n",
    "        if y == sector_name:\n",
    "            conf_list = pred_df.loc[sector_name, 'forecast_conf']\n",
    "            pred_list = pred_df.loc[sector_name, 'forecast_vals']\n",
    "            lower_conf = []\n",
    "            upper_conf = []\n",
    "            for x in range(len(conf_list)):\n",
    "                lower_conf.append(conf_list[x,0])\n",
    "                upper_conf.append(conf_list[x,1])\n",
    "            y2 = list(np.array(sectval_df[sector_name])*scalar)\n",
    "            x_values = list(sectval_df['date'])\n",
    "            x_values.extend(forecast_dates)\n",
    "            x_rev = x_values[::-1]\n",
    "            y1 = none_list[:-1]\n",
    "            y1.append(y2[-1])\n",
    "            y1.extend(np.array(pred_list)*scalar)\n",
    "            y1_upper = none_list[:-1]\n",
    "            y1_upper.append(y2[-1])\n",
    "            y1_upper.extend(np.array(upper_conf)*scalar)\n",
    "            y1_lower = none_list[:-1]\n",
    "            y1_lower.append(y2[-1])\n",
    "            y1_lower.extend(np.array(lower_conf)*scalar)\n",
    "            y1_lower = y1_lower[::-1]\n",
    "            y2.extend(none_list[:5])\n",
    "            forecast_sect = round(y1[-1], 2)\n",
    "        elif y == sector_stocks:\n",
    "            conf_list = stock_pred_df.loc[sector_stocks, 'forecast_conf']\n",
    "            pred_list = stock_pred_df.loc[sector_stocks, 'forecast_vals']\n",
    "            lower_conf = []\n",
    "            upper_conf = []\n",
    "            for x in range(len(conf_list)):\n",
    "                lower_conf.append(conf_list[x,0])\n",
    "                upper_conf.append(conf_list[x,1])\n",
    "            y2 = list(stockval_df[sector_stocks])\n",
    "            x_values = list(sectval_df['date'])\n",
    "            x_values.extend(forecast_dates)\n",
    "            x_rev = x_values[::-1]\n",
    "            y1 = none_list[:-1]\n",
    "            y1.append(y2[-1])\n",
    "            y1.extend(pred_list)\n",
    "            y1_upper = none_list[:-1]\n",
    "            y1_upper.append(y2[-1])\n",
    "            y1_upper.extend(upper_conf)\n",
    "            y1_lower = none_list[:-1]\n",
    "            y1_lower.append(y2[-1])\n",
    "            y1_lower.extend(lower_conf)\n",
    "            y1_lower = y1_lower[::-1]\n",
    "            y2.extend(none_list[:5])\n",
    "            forecast_stock = round(y1[-1], 2)\n",
    "        \n",
    "        if y == sector_name:\n",
    "            fig.add_trace(go.Scatter(x=x_values+x_rev,\n",
    "                y=y1_upper+y1_lower, fill='toself',\n",
    "                fillcolor='rgba(0,100,80,0.2)',\n",
    "                line_color='rgba(255,255,255,0)',showlegend=False), row=2, col=1)\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y1,\n",
    "                line_color='rgb(0,100,80)', name='Sector forecast'), row=2, col=1)\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y2,\n",
    "                line_color='rgb(0,176,246)', name=sector_name), row=2, col=1)\n",
    "        elif y == sector_stocks:\n",
    "            fig.add_trace(go.Scatter(x=x_values+x_rev,\n",
    "                y=y1_upper+y1_lower, fill='toself',\n",
    "                fillcolor='rgba(0,100,80,0.2)',\n",
    "                line_color='rgba(255,255,255,0)',showlegend=False), row=2, col=1)\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y1,\n",
    "                line_color='rgb(0,100,80)', name='Stock forecast'), row=2, col=1)\n",
    "            fig.add_trace(go.Scatter(x=x_values, y=y2,\n",
    "                line_color='rgb(50,20,80)', name='Stock: '+sector_stocks), row=2, col=1)\n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            header=dict(\n",
    "                values=['Stock/Sector', 'Last Value', 'Forecast Value', 'Percent Change'],\n",
    "                align=\"left\"),\n",
    "            cells=dict(\n",
    "                values=[[sector_stocks,sector_name], [stock_last,sect_last], [forecast_stock,forecast_sect],\\\n",
    "                        [round((forecast_stock-stock_last)/stock_last*100,2), \\\n",
    "                         round((forecast_sect-sect_last)/sect_last*100,2)]],\\\n",
    "                align = \"left\")), row=1, col=1)\n",
    "    fig.update_traces(mode='lines', hovertemplate=None, row=2, col=1)\n",
    "    fig.update_xaxes(rangeslider_visible=True, row=2, col=1)\n",
    "    fig.update_layout(\n",
    "        title='Five Day Forecast - Stock vs. Sector', xaxis_title='Date',\n",
    "        yaxis_title='Stock Value', hovermode=\"x\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting final dropdown menu\n",
    "#Defining final interface function\n",
    "graph_type = widgets.Dropdown(options=[('Stock vs. Sector', stock_vs_sector), \\\n",
    "                                       ('Stock vs. Sector w/ Table', stock_vs_sector_table),\\\n",
    "                                       ('LSTM Forecasts', lstm_forecast), \\\n",
    "                                       ('Compare Sectors', sector_compare), \\\n",
    "                                       ('One Step Ahead Forecast', step_ahead_forecast), \\\n",
    "                                    ('Yield vs. Stock Value', yield_stock), \\\n",
    "                                      ('Yield vs. Sector', yield_sect)], \\\n",
    "                                     description='Graph Type')\n",
    "\n",
    "def graph_picker(graph_type):\n",
    "    if graph_type == stock_vs_sector:\n",
    "        interact(stock_vs_sector, sector_name=sector_name, sector_stocks=sector_stocks)\n",
    "    elif graph_type == stock_vs_sector_table:\n",
    "        interact(stock_vs_sector_table, sector_name=sector_name, sector_stocks=sector_stocks)\n",
    "    elif graph_type == lstm_forecast:\n",
    "        interact(lstm_forecast, random_stocks=random_stocks)\n",
    "    elif graph_type == sector_compare:\n",
    "        interact(sector_compare)\n",
    "    elif graph_type == step_ahead_forecast:\n",
    "        interact(step_ahead_forecast, stock_symbol=stock_symbol)\n",
    "    elif graph_type == yield_stock:\n",
    "        interact(yield_stock, stock_symbol=stock_symbol, yield_curve=yield_curve)\n",
    "    elif graph_type == yield_sect:\n",
    "        interact(yield_sect, sector_name=sector_name, yield_curve=yield_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - The Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9314455b80e547659fa633cbb9c3cb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Graph Type', options=(('Stock vs. Sector', <function stock_vs_sect…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(graph_picker, graph_type=graph_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "In this section I will briefly explain what the interface can do and the purpose of each graph.\n",
    "\n",
    "1. Stock vs. Sector - On this graph you choose a sector, and the stocks associated with that sector can be chosen as well.  The stock value and sector index value are plotted, along with their 5-day predictions and confidence intervals. The sector value is scaled so that it has the same starting value as the stock.  There is a slider on the bottom to adjust the date range you would like to view.  Can be used to easily gauge whether a stock is outperforming its sector, as well as to see a 5-day prediction.  \n",
    "2. Stock vs. Sector w/ Table - Same as above, but also returns a table showing the predicted percent change in value for both the sector index and stock. \n",
    "3. LSTM Forecasts - Plots the actual test value as well as the predicted value of selected stocks using LSTM.  It also returns the root mean squared error.  Can be compared to the One Step Ahead to see which model is more accurate with its predictions.\n",
    "4. Compare Sectors - This graph shows the performance of each sector over the past year, with each index starting at 100.  Hovering over it makes all of the names appear from highest to lowest at that particular date. Easy to see which sectors are performing well and which ones are not.  \n",
    "5. One Step Ahead Forecast - Plots the selected stock, along with its one step ahead prediction and confidence interval. Can be compared to the LSTM to give an idea of which model makes the better predictions.  \n",
    "6. Yield vs. Stock Value - Plots the stock of your choice along with your choice of yield curve.  Makes it easy to see any potential relationships between stocks and yield spreads.  Also has a date slider at the bottom\n",
    "7. Yield vs. Sector Value - Plots the sector index of your choice along with your choice of yield curve.  Makes it easy to see any potential relationships between sector averages and yield spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
